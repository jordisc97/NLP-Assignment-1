{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_rows', 25)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ffill we optimize the code. It will fill all missing values with the previous non-nan value\n",
    "data = pd.read_csv(\"data/kaggle_ner/ner_dataset.csv\",\n",
    "                   encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available TAGS:\n",
      "{'I-eve', 'I-art', 'I-gpe', 'I-tim', 'B-eve', 'I-per', 'O', 'B-art', 'B-nat', 'B-geo', 'B-per', 'B-gpe', 'I-geo', 'B-org', 'I-org', 'I-nat', 'B-tim'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Available TAGS:\")\n",
    "print(set(data[\"Tag\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAG        | Examples            \n",
      "------------------------------------------------------------\n",
      "I-eve      | Summer               Olympics             Olympic             \n",
      "I-art      | Non-Proliferation    V-6                  Simple              \n",
      "I-gpe      | States               Korea                Binh                \n",
      "I-tim      | 8                    1                    2                   \n",
      "B-eve      | 2012                 Games                Games               \n",
      "I-per      | Mahmoud              Ahmadinejad          Horbach             \n",
      "O          | Thousands            of                   demonstrators       \n",
      "B-art      | Nuclear              Saltillo             Pentastar           \n",
      "B-nat      | H5N1                 H5N1                 Jing                \n",
      "B-geo      | London               Iraq                 Hyde                \n",
      "B-per      | Bush                 President            Thomas              \n",
      "B-gpe      | British              English              Britain             \n",
      "I-geo      | Park                 State                State               \n",
      "B-org      | Labor                International        IAEA                \n",
      "I-org      | Party                Atomic               Energy              \n",
      "I-nat      | Jing                 Jing                 Acute               \n",
      "B-tim      | Wednesday            Wednesday            Tuesday             \n"
     ]
    }
   ],
   "source": [
    "print(\"{:10s} | {:20s}\".format(\"TAG\", \"Examples\"))\n",
    "print(\"-\"*60)\n",
    "for tag in set(data[\"Tag\"]):\n",
    "    print(\"{:10s} | {:20s} {:20s} {:20s}\".format(tag, *data[data[\"Tag\"] == tag][\"Word\"][0:3].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47959"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sentences = len(data['Sentence #'].unique())\n",
    "n_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.56 s\n",
      "Wall time: 4.53 s\n"
     ]
    }
   ],
   "source": [
    "# Using groupby and apply rather than a for loop the computation is reduced from +2h to 4s\n",
    "%time X_txt = list(data.groupby(\"Sentence #\")['Word'].apply(list))\n",
    "%time Y_txt = list(data.groupby(\"Sentence #\")['Tag'].apply(list))\n",
    "\n",
    "from skseq.sequences.label_dictionary import LabelDictionary\n",
    "x_dict = LabelDictionary(label_names=data['Word'].unique())\n",
    "y_dict = LabelDictionary(label_names=data['Tag'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "import skseq\n",
    "import skseq.sequences\n",
    "import skseq.readers\n",
    "from skseq.sequences import sequence\n",
    "from skseq.sequences import sequence_list\n",
    "from skseq.sequences import label_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_split = 35971\n",
    "X_train_txt, X_test_txt, Y_train_txt, Y_test_txt = X_txt[:n_split], X_txt[n_split:], Y_txt[:n_split], Y_txt[n_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skseq.sequences.sequence_list import SequenceList\n",
    "from skseq.sequences.sequence import Sequence\n",
    "\n",
    "# train_sequences = [Sequence(x,y) for x,y in zip(X_train_txt, Y_train_txt)]\n",
    "# test_sequences = [Sequence(x,y) for x,y in zip(X_test_txt, Y_test_txt)]\n",
    "\n",
    "train_seq_list = SequenceList(x_dict, y_dict)\n",
    "for x,y in zip(X_train_txt, Y_train_txt):\n",
    "    train_seq_list.add_sequence(x, y, x_dict, y_dict)\n",
    "\n",
    "test_seq_list = SequenceList(x_dict, y_dict)\n",
    "for x,y in zip(X_test_txt, Y_test_txt):\n",
    "    test_seq_list.add_sequence(x, y, x_dict, y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dict length: 38298\n",
      "Feature list length: 35971\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-142e70a217f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# Make predictions for the various sequences using the trained model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mpred_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviterbi_decode_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_seq_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mpred_test\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviterbi_decode_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_seq_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\UB\\NLP-Assignment-1\\deliverable_2\\skseq\\sequences\\sequence_classifier.py\u001b[0m in \u001b[0;36mviterbi_decode_corpus\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msequence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m             \u001b[0mpredicted_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviterbi_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_sequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\UB\\NLP-Assignment-1\\deliverable_2\\skseq\\sequences\\sequence_classifier.py\u001b[0m in \u001b[0;36mviterbi_decode\u001b[1;34m(self, sequence)\u001b[0m\n\u001b[0;32m    134\u001b[0m                                                             \u001b[0mtransition_scores\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                                                             \u001b[0mfinal_scores\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                                                             emission_scores)\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mpredicted_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\UB\\NLP-Assignment-1\\deliverable_2\\skseq\\sequences\\sequence_classification_decoder.py\u001b[0m in \u001b[0;36mrun_viterbi\u001b[1;34m(self, initial_scores, transition_scores, final_scores, emission_scores)\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[0mviterbi_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0memission_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[0mviterbi_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m                     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mviterbi_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtransition_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[1;31m# Termination.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mbest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mviterbi_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfinal_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m     \"\"\"\n\u001b[1;32m-> 1186\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feature_mapper = skseq.sequences.id_feature.IDFeatures(train_seq_list)\n",
    "feature_mapper.build_features()\n",
    "\n",
    "print('Feature dict length:', len(feature_mapper.feature_dict))\n",
    "print('Feature list length:', len(feature_mapper.feature_list))\n",
    "\n",
    "import skseq.sequences.structured_perceptron as spc\n",
    "# sp = spc.StructuredPerceptron(corpus.word_dict, corpus.tag_dict, feature_mapper)\n",
    "sp = spc.StructuredPerceptron(x_dict, y_dict, feature_mapper)\n",
    "\n",
    "num_epochs = 5\n",
    "%time sp.fit(train_seq_list, num_epochs)\n",
    "\n",
    "def evaluate_corpus(sequences, sequences_predictions):\n",
    "    \"\"\"Evaluate classification accuracy at corpus level, comparing with\n",
    "    gold standard.\"\"\"\n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        pred = sequences_predictions[i]\n",
    "        for j, y_hat in enumerate(pred.y):\n",
    "            if sequence.y[j] == y_hat:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    return correct / total\n",
    "\n",
    "# Make predictions for the various sequences using the trained model.\n",
    "pred_train = sp.viterbi_decode_corpus(train_seq_list)\n",
    "pred_test  = sp.viterbi_decode_corpus(test_seq_list)\n",
    "\n",
    "# Evaluate and print accuracies\n",
    "eval_train = evaluate_corpus(train_seq_list.seq_list, pred_train)\n",
    "eval_test = evaluate_corpus(test_seq_list.seq_list, pred_test)\n",
    "\n",
    "print(\"SP -  Accuracy Train: %.3f Test: %.3f\"%(eval_train, eval_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0/0 1/0 2/0 3/0 4/0 5/0 6/1 7/0 8/0 9/0 10/0 11/0 12/1 13/0 14/0 9/0 15/0 1/0 16/2 17/0 18/0 19/0 20/0 21/0 "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = train_seq_list[0]\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0/0 1/0 2/0 3/0 4/0 5/0 6/0 7/0 8/0 9/0 10/0 11/0 12/0 13/0 14/0 9/0 15/0 1/0 16/0 17/0 18/0 19/0 20/0 21/0 ,\n",
       " 0.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.viterbi_decode(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8462011121693447"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "pred_test  = sp.viterbi_decode_corpus(test_seq_list)\n",
    "eval_test = evaluate_corpus(test_seq_list.seq_list, pred_test)\n",
    "eval_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
