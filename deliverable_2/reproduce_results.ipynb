{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Results notebook\n",
    "+ Here the results have to be shown without David having to wait 1h 30mins til the model trains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do:\n",
    "+ Pickle of the HMM model (Done - Jordi)\n",
    "+ Fix the HiddenMarkovModel.py so the HMM code called from there\n",
    "+ Implement the Edit_dist for the closes word to work in the test\n",
    "+ Check the results for the extended_feature\n",
    "+ Pickle of BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sctructure:\n",
    "+ Read data\n",
    "+ Spell checker\n",
    "+ HMM\n",
    "+ Id fetures\n",
    "+ Structured Perceptron (Notebook: Structured_Perceptron_Validation)\n",
    "+ BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:43:11.016579Z",
     "start_time": "2020-05-05T15:43:11.012243Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import editdistance\n",
    "import itertools\n",
    "\n",
    "# from HiddenMarkovModel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_rows', 25)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:43:22.865464Z",
     "start_time": "2020-05-05T15:43:22.482990Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using ffill we optimize the code. It will fill all missing values with the previous non-nan value\n",
    "data = pd.read_csv(\"data/kaggle_ner/ner_dataset.csv\",\n",
    "                   encoding=\"latin1\").fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:43:50.431431Z",
     "start_time": "2020-05-05T15:43:50.418337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:25.213336Z",
     "start_time": "2020-05-05T14:07:25.153708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available TAGS:\n",
      "{'B-org', 'I-art', 'I-per', 'B-geo', 'I-gpe', 'B-nat', 'I-nat', 'B-eve', 'B-gpe', 'B-art', 'I-org', 'I-geo', 'I-eve', 'B-tim', 'I-tim', 'B-per', 'O'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Available TAGS:\")\n",
    "print(set(data[\"Tag\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:26.407180Z",
     "start_time": "2020-05-05T14:07:25.694653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAG        | Examples            \n",
      "------------------------------------------------------------\n",
      "B-org      | Labor                International        IAEA                \n",
      "I-art      | Non-Proliferation    V-6                  Simple              \n",
      "I-per      | Mahmoud              Ahmadinejad          Horbach             \n",
      "B-geo      | London               Iraq                 Hyde                \n",
      "I-gpe      | States               Korea                Binh                \n",
      "B-nat      | H5N1                 H5N1                 Jing                \n",
      "I-nat      | Jing                 Jing                 Acute               \n",
      "B-eve      | 2012                 Games                Games               \n",
      "B-gpe      | British              English              Britain             \n",
      "B-art      | Nuclear              Saltillo             Pentastar           \n",
      "I-org      | Party                Atomic               Energy              \n",
      "I-geo      | Park                 State                State               \n",
      "I-eve      | Summer               Olympics             Olympic             \n",
      "B-tim      | Wednesday            Wednesday            Tuesday             \n",
      "I-tim      | 8                    1                    2                   \n",
      "B-per      | Bush                 President            Thomas              \n",
      "O          | Thousands            of                   demonstrators       \n"
     ]
    }
   ],
   "source": [
    "print(\"{:10s} | {:20s}\".format(\"TAG\", \"Examples\"))\n",
    "print(\"-\"*60)\n",
    "for tag in set(data[\"Tag\"]):\n",
    "    print(\"{:10s} | {:20s} {:20s} {:20s}\".format(tag, *data[data[\"Tag\"] == tag][\"Word\"][0:3].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using groupby and apply rather than a for loop the computation is reduced from +2h to 4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.77 s\n",
      "Wall time: 5.11 s\n"
     ]
    }
   ],
   "source": [
    "%time X_txt = list(data.groupby(\"Sentence #\")['Word'].apply(list))\n",
    "%time Y_txt = list(data.groupby(\"Sentence #\")['Tag'].apply(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:15.567398Z",
     "start_time": "2020-05-05T14:08:15.563916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands/O of/O demonstrators/O have/O marched/O through/O London/B-geo to/O protest/O the/O war/O in/O Iraq/B-geo and/O demand/O the/O withdrawal/O of/O British/B-gpe troops/O from/O that/O country/O ./O'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "xy = [\"{}/{}\".format(x,y) for x,y in zip(X_txt[i],Y_txt[i])]\n",
    "\" \".join(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 35178 words in the dictionary.\n",
      "And 47959 unique sentences.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", len(data[\"Word\"].unique()), \"words in the dictionary.\")\n",
    "print(\"And\", len(data['Sentence #'].unique()), \"unique sentences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word to pos and tag to pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:15.573987Z",
     "start_time": "2020-05-05T14:08:15.569071Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_word_to_pos(X):\n",
    "    word_to_pos = {k: i for i, k in enumerate(X['Word'].unique())}               \n",
    "    pos_to_word = {v: k for k, v in word_to_pos.items()}\n",
    "    return word_to_pos, pos_to_word\n",
    "            \n",
    "def build_tag_to_pos(Y):\n",
    "    tag_to_pos = {k: i for i, k in enumerate(Y['Tag'].unique())} \n",
    "    pos_to_tag = {v: k for k, v in tag_to_pos.items()}\n",
    "\n",
    "    return tag_to_pos, pos_to_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:15.584465Z",
     "start_time": "2020-05-05T14:08:15.575588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35178, 17)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_pos, pos_to_word = build_word_to_pos(data)\n",
    "tag_to_pos, pos_to_tag  = build_tag_to_pos(data)\n",
    "\n",
    "len(word_to_pos), len(tag_to_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:15.603562Z",
     "start_time": "2020-05-05T14:08:15.592209Z"
    }
   },
   "outputs": [],
   "source": [
    "X = [[word_to_pos[w] for w in s] for s in X_txt]\n",
    "Y = [[tag_to_pos[t] for t in s] for s in Y_txt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "# From .py\n",
    "from HiddenMarkovModel import *\n",
    "\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "import skseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skseq\n",
    "import skseq.sequences\n",
    "import skseq.readers\n",
    "\n",
    "from skseq.sequences import sequence\n",
    "from skseq.sequences import sequence_list\n",
    "from skseq.sequences import label_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_split = 35971\n",
    "X_train_txt, X_test_txt, Y_train_txt, Y_test_txt = X_txt[:n_split], X_txt[n_split:], Y_txt[:n_split], Y_txt[n_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logzero():\n",
    "    return -np.inf\n",
    "\n",
    "\n",
    "def safe_log(x):\n",
    "    print(x)\n",
    "    if x == 0:\n",
    "        return logzero()\n",
    "    return np.log(x)\n",
    "\n",
    "\n",
    "def logsum_pair(logx, logy):\n",
    "    \"\"\"\n",
    "    Return log(x+y), avoiding arithmetic underflow/overflow.\n",
    "\n",
    "    logx: log(x)\n",
    "    logy: log(y)\n",
    "\n",
    "    Rationale:\n",
    "\n",
    "    x + y    = e^logx + e^logy\n",
    "             = e^logx (1 + e^(logy-logx))\n",
    "    log(x+y) = logx + log(1 + e^(logy-logx)) (1)\n",
    "\n",
    "    Likewise,\n",
    "    log(x+y) = logy + log(1 + e^(logx-logy)) (2)\n",
    "\n",
    "    The computation of the exponential overflows earlier and is less precise\n",
    "    for big values than for small values. Due to the presence of logy-logx\n",
    "    (resp. logx-logy), (1) is preferred when logx > logy and (2) is preferred\n",
    "    otherwise.\n",
    "    \"\"\"\n",
    "    if logx == logzero():\n",
    "        return logy\n",
    "    elif logx > logy:\n",
    "        return logx + np.log1p(np.exp(logy-logx))\n",
    "    else:\n",
    "        return logy + np.log1p(np.exp(logx-logy))\n",
    "\n",
    "\n",
    "def logsum(logv):\n",
    "    \"\"\"\n",
    "    Return log(v[0]+v[1]+...), avoiding arithmetic underflow/overflow.\n",
    "    \"\"\"\n",
    "    res = logzero()\n",
    "    for val in logv:\n",
    "        res = logsum_pair(res, val)\n",
    "    return res\n",
    "\n",
    "class HMM(object):\n",
    "    \n",
    "    def __init__(self, word_to_pos={}, state_to_pos={}):\n",
    "        self.fitted = False\n",
    "        self.counts = {\"emission\": None, \"transition\":None, \"final\":None, \"initial\":None}\n",
    "        self.probs  = {\"emission\": None, \"transition\":None, \"final\":None, \"initial\":None}\n",
    "        self.scores = {\"emission\": None, \"transition\":None, \"final\":None, \"initial\":None}\n",
    "        self.decode = set([\"posterior\", \"viterbi\"])\n",
    "        self.word_to_pos  = word_to_pos\n",
    "        self.state_to_pos = state_to_pos\n",
    "        self.pos_to_word  = {v: k for k, v in word_to_pos.items()}\n",
    "        self.pos_to_state = {v: k for k, v in state_to_pos.items()}\n",
    "    \n",
    "        self.n_states     = len(state_to_pos)\n",
    "        self.n_words      = len(word_to_pos)\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, observation_lables: list, state_labels: list):\n",
    "        \"\"\"\n",
    "        Computes and saves: counts, probs, scores.\n",
    "        \"\"\"\n",
    "        if self.state_to_pos is None or self.word_to_pos is None:\n",
    "            print(\"Error state_to_pos or word_to_pos needed to be defined\")\n",
    "            return\n",
    "            \n",
    "        self.counts = self.sufficient_statistics_hmm(observation_lables, state_labels)       \n",
    "        self.probs  = self.compute_probs(self.counts)  \n",
    "        self.scores = self.compute_scores(self.probs)  \n",
    "        self.fitted = True\n",
    "        \n",
    "    def sufficient_statistics_hmm(self, observation_lables, state_labels):\n",
    "\n",
    "        state_to_pos, word_to_pos = self.state_to_pos, self.word_to_pos\n",
    "        \n",
    "        def update_initial_counts(initial_counts, seq_x, state_to_pos):\n",
    "            initial_counts[state_to_pos[seq_x[0]]] +=  1\n",
    "            \n",
    "        def update_transition_counts(transition_counts, seq_y, state_to_pos):\n",
    "            for (t_prev, t) in zip(seq_y[:-1], seq_y[1:]):\n",
    "                transition_counts[state_to_pos[t], state_to_pos[t_prev]] += 1 \n",
    "\n",
    "        def update_emission_counts(emission_counts, seq_x, seq_y, state_to_pos, word_to_pos):\n",
    "            for (t,x) in zip(seq_y, seq_x):\n",
    "                emission_counts[state_to_pos[t], word_to_pos[x]] += 1 \n",
    "                \n",
    "        def update_final_counts(final_counts, seq_y, state_to_pos):\n",
    "            final_counts[state_to_pos[seq_y[-1]]] +=1\n",
    "\n",
    "        n_states = len(state_to_pos)\n",
    "        n_words  = len(word_to_pos)\n",
    "        initial_counts      = np.zeros((n_states))\n",
    "        transition_counts   = np.zeros((n_states, n_states))\n",
    "        final_counts        = np.zeros((n_states))\n",
    "        emission_counts     = np.zeros((n_states, n_words))\n",
    "\n",
    "        for seq_x, seq_y in zip(observation_lables, state_labels):\n",
    "            update_initial_counts(initial_counts, seq_y, state_to_pos)\n",
    "            update_transition_counts(transition_counts, seq_y,  state_to_pos)\n",
    "            update_emission_counts(emission_counts, seq_x, seq_y, state_to_pos, word_to_pos) \n",
    "            update_final_counts(final_counts, seq_y,  state_to_pos) \n",
    "\n",
    "        return {\"emission\":   emission_counts, \n",
    "                \"transition\": transition_counts,\n",
    "                \"final\":      final_counts, \n",
    "                \"initial\":    initial_counts}\n",
    "    \n",
    "    def compute_probs(self, counts):\n",
    "        \n",
    "        initial_counts    = counts['initial']\n",
    "        transition_counts = counts['transition']\n",
    "        emission_counts   = counts['emission']\n",
    "        final_counts      = counts['final']\n",
    "\n",
    "        initial_probs    = (initial_counts / np.sum(initial_counts))\n",
    "        transition_probs = transition_counts/(np.sum(transition_counts,0) + final_counts)\n",
    "        final_probs      = final_counts/(np.sum(transition_counts, 0) + final_counts )\n",
    "        emission_probs   = (emission_counts.T / np.sum(emission_counts, 1)).T\n",
    "    \n",
    "        return {\"emission\":   emission_probs, \n",
    "                \"transition\": transition_probs,\n",
    "                \"final\":      final_probs, \n",
    "                \"initial\":    initial_probs}\n",
    "    \n",
    "    def compute_scores(self, probs):\n",
    "         return {\"emission\":   np.log(probs[\"emission\"]), \n",
    "                 \"transition\": np.log(probs[\"transition\"]),\n",
    "                 \"final\":      np.log(probs[\"final\"]), \n",
    "                 \"initial\":    np.log(probs[\"initial\"])}\n",
    "        \n",
    "    def forward_computations(self, x: list):\n",
    "        forward_x = None\n",
    "        return forward_x\n",
    "    \n",
    "    def backward_computations(self, x:list):\n",
    "        backward_x = None\n",
    "        return backward_x\n",
    "    \n",
    "    def log_forward_computations(self, x: list):\n",
    "        \"\"\"\n",
    "        Compute the log_forward computations\n",
    "\n",
    "        Assume there are S possible states and a sequence of length N.\n",
    "        This method will compute iteritavely the log_forward quantities.\n",
    "\n",
    "        * log_f is a S x N Array.\n",
    "        * log_f_x[:,i] will contain the forward quantities at position i.\n",
    "        * log_f_x[:,i] is a vector of size S.\n",
    "        \n",
    "        Returns\n",
    "        - log_f_x: Array of size K x N\n",
    "        \"\"\" \n",
    "        n_x = len(x)\n",
    "        \n",
    "        # log_f_x initialized to -Inf because log(0) = -Inf\n",
    "        log_f_x = np.zeros((self.n_states, n_x)) - np.Inf\n",
    "        x_emission_scores = np.array([hmm.scores['emission'][:, hmm.word_to_pos[w]] for w in x]).T\n",
    "        \n",
    "        log_f_x[:,0] = x_emission_scores[:, 0] + self.scores['initial']\n",
    "        for n in range(1, n_x):\n",
    "            for s in range(self.n_states):\n",
    "                log_f_x[s,n] = logsum(log_f_x[:,n-1] + self.scores['transition'][s,:]) + x_emission_scores[s,n]\n",
    "\n",
    "        log_likelihood = logsum(log_f_x[:,n_x-1] + self.scores['final']) \n",
    "        return log_f_x, log_likelihood # log(P(X=x))\n",
    "    \n",
    "    \n",
    "    def log_backward_computations(self, x: list):\n",
    "        n_x = len(x)\n",
    "        \n",
    "        # log_f_x initialized to -Inf because log(0) = -Inf\n",
    "        log_b_x = np.zeros((self.n_states, n_x)) - np.Inf\n",
    "        x_emission_scores = np.array([hmm.scores['emission'][:, hmm.word_to_pos[w]] for w in x]).T\n",
    "        log_b_x[:,-1] = self.scores['final']\n",
    "\n",
    "        for n in range(n_x-2, -1, -1):\n",
    "            for s in range(self.n_states):\n",
    "                log_b_x[s,n] = logsum(log_b_x[:,n+1] + self.scores['transition'][:,s] + x_emission_scores[:,n+1])\n",
    "\n",
    "        log_likelihood = logsum(log_b_x[:,0] + self.scores['initial'] + x_emission_scores[:,0]) \n",
    "        return log_b_x, log_likelihood  # log(P(X=x))\n",
    "        \n",
    "    def predict_labels(self, x: list, decode=\"posterior\"):\n",
    "        \"\"\"\n",
    "        Retuns a sequence of states for each word in **x**.\n",
    "        The output depends on the **decode** method chosen.\n",
    "        \"\"\"\n",
    "        assert decode in self.decode, \"decode `{}` is not valid\".format(decode)\n",
    "        \n",
    "        if decode is 'posterior':\n",
    "            return self.posterior_decode(x)\n",
    "        \n",
    "        if decode is 'viterbi':\n",
    "            return self.viterbi_decode(x)\n",
    "\n",
    "    def compute_state_posteriors(self, x:list):\n",
    "        log_f_x, log_likelihood = self.log_forward_computations(x)\n",
    "        log_b_x, log_likelihood = self.log_backward_computations(x)\n",
    "        state_posteriors = np.zeros((self.n_states, len(x)))\n",
    "        \n",
    "        for pos in range(len(x)):\n",
    "            state_posteriors[:, pos] = log_f_x[:, pos] + log_b_x[:, pos] - log_likelihood\n",
    "        return state_posteriors\n",
    "\n",
    "    def posterior_decode(self, x: list, decode_states=True):\n",
    "        \n",
    "        state_posteriors = self.compute_state_posteriors(x)\n",
    "        y_hat = state_posteriors.argmax(axis=0)\n",
    "        \n",
    "        if decode_states:\n",
    "            y_hat = [hmm.pos_to_state[y] for y in y_hat]\n",
    "            \n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "hmm = pickle.load(open( \"HMM.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_hmm():\n",
    "    tot = 0\n",
    "    err = 0\n",
    "\n",
    "    mstks = []\n",
    "    correct = []\n",
    "\n",
    "    tbar = tqdm(X_test_txt)\n",
    "    for i, xtest in enumerate(tbar):\n",
    "        pred = hmm.predict_labels(xtest)\n",
    "        yral = Y_test_txt[i]\n",
    "\n",
    "        s = sum(v1!=v2 for v1,v2 in list(zip(pred, yral)))\n",
    "        err+= s\n",
    "        tot+=len(yral)\n",
    "\n",
    "        toappend = mstks if s!=0 else correct\n",
    "        toappend.append(pd.DataFrame([xtest, pred, yral]))\n",
    "        tbar.set_description(\"Accuracy: {:6.4f}\".format(1-err/tot))\n",
    "    return correct, mstks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1522ae082b4ce089e4bf795f5e50b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11988.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toti\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:210: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct, mstks = evaluate_hmm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mstks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skseq.sequences.sequence_list import SequenceList\n",
    "from skseq.sequences.sequence import Sequence\n",
    "from skseq.sequences.label_dictionary import LabelDictionary\n",
    "\n",
    "x_dict = LabelDictionary(label_names=data['Word'].unique())\n",
    "y_dict = LabelDictionary(label_names=data['Tag'].unique())\n",
    "\n",
    "# train_sequences = [Sequence(x,y) for x,y in zip(X_train_txt, Y_train_txt)]\n",
    "# test_sequences = [Sequence(x,y) for x,y in zip(X_test_txt, Y_test_txt)]\n",
    "\n",
    "train_seq_list = SequenceList(x_dict, y_dict)\n",
    "for x,y in zip(X_train_txt, Y_train_txt):\n",
    "    train_seq_list.add_sequence(x, y, x_dict, y_dict)\n",
    "\n",
    "test_seq_list = SequenceList(x_dict, y_dict)\n",
    "for x,y in zip(X_test_txt, Y_test_txt):\n",
    "    test_seq_list.add_sequence(x, y, x_dict, y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BK_Tree():    \n",
    "    def __init__(self, documents):\n",
    "        self.root = Node(documents[0][0])\n",
    "        for seq in documents:\n",
    "            for word in seq:\n",
    "                self.root.append(word)\n",
    "        \n",
    "    def append(self, word):\n",
    "        self.root.append(word)\n",
    "        \n",
    "    def is_in_corpus(self, new_word):\n",
    "        return self.root.is_in_corpus(new_word)\n",
    "        \n",
    "        \n",
    "class Node():    \n",
    "    def __init__(self, word):\n",
    "        self.word = word\n",
    "        self.dict_dist = {}\n",
    "    \n",
    "    def is_in_corpus(self, new_word):\n",
    "        if self.word == new_word:\n",
    "            return True\n",
    "        dist = editdistance.eval(self.word, new_word)\n",
    "        if dist not in self.dict_dist:\n",
    "            return False\n",
    "        return self.dict_dist[dist].is_in_corpus(new_word)\n",
    "    \n",
    "    def append(self, new_word):\n",
    "        dist = editdistance.eval(self.word, new_word)\n",
    "        if dist not in self.dict_dist:\n",
    "            if self.word!=new_word:\n",
    "                self.dict_dist[dist] = Node(new_word)\n",
    "        else:\n",
    "            self.dict_dist[dist].append(new_word)    \n",
    "            \n",
    "            \n",
    "def edit_ditance_word(mistake, X_train_txt):\n",
    "    # mistake = \"Barchelona\" \n",
    "    corpus = [w for seq in X_train_txt for w in seq]\n",
    "    distances = [editdistance.eval(mistake, word) for word in corpus]\n",
    "    return corpus[np.argmin(distances)], min(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can improve the results adding more features\n",
    "\n",
    "# from skseq.sequences import extended_feature\n",
    "# feature_mapper = skseq.sequences.extended_feature.ExtendedFeatures(train_seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mapper = skseq.sequences.id_feature.IDFeatures(train_seq_list)\n",
    "feature_mapper.build_features()\n",
    "\n",
    "print('Feature dict length:', len(feature_mapper.feature_dict))\n",
    "print('Feature list length:', len(feature_mapper.feature_list))\n",
    "\n",
    "import skseq.sequences.structured_perceptron_validation as spc\n",
    "# sp = spc.StructuredPerceptron(corpus.word_dict, corpus.tag_dict, feature_mapper)\n",
    "sp = spc.StructuredPerceptronValidation(x_dict, y_dict, feature_mapper, averaged=False)\n",
    "\n",
    "\n",
    "def train_perceptron(load_no_fit = True, num_epochs = 50, epochs_before_stopping = 5, dir_to_params = './'):\n",
    "    if not load_no_fit:\n",
    "        print('Training for %i epochs with early stopping after %i epochs of no improvement' % (num_epochs, epochs_before_stopping))\n",
    "#         %time sp.fit(dummy_seq_list, val_seq_list, num_epochs, epochs_before_stopping, dir_to_params)\n",
    "        %time sp.fit(train_seq_list, test_seq_list, num_epochs, epochs_before_stopping, dir_to_params)\n",
    "    else:\n",
    "        sp.load_model(dir_to_params)\n",
    "        \n",
    "        \n",
    "import pandas as pd\n",
    "from IPython.core import display as ICD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_perceptron():\n",
    "    # Make predictions for the various sequences using the trained model.\n",
    "    pred_train = sp.viterbi_decode_corpus(train_seq_list)\n",
    "    pred_test  = sp.viterbi_decode_corpus(test_seq_list)\n",
    "\n",
    "    # Evaluate and print accuracies\n",
    "    eval_train = evaluate_corpus(train_seq_list.seq_list, pred_train)\n",
    "    eval_test = evaluate_corpus(test_seq_list.seq_list, pred_test)\n",
    "\n",
    "    print(\"SP -  Accuracy Train: %.3f Test: %.3f\"%(eval_train, eval_test))\n",
    "    \n",
    "def predict_text_tags(seq, nice_format=False, change_word=False, sensibility=2):\n",
    "    assert isinstance(seq, str) or isinstance(seq, list), \"The input must be a sentence (string format or a list of words)\"\n",
    "    corpus = list(itertools.chain(*X_train_txt)) ###\n",
    "    \n",
    "    if isinstance(seq, str):\n",
    "        seq = seq.split()      \n",
    "    \n",
    "    num2lab = {v:k for k,v in sp.state_labels.items()}\n",
    "    if nice_format:\n",
    "        grp = pd.DataFrame([seq, [num2lab[w] for w in sp.predict_tags_given_words(seq)]], \n",
    "                           index=[\"Words\", \"Tags\"], columns=[\"W_{:02d}\".format(i) for i in range(len(seq))])   \n",
    "        grp = grp.style.applymap(lambda x: 'color: blue' if x != 'O' and x in sp.state_labels else 'color: black')\n",
    "        ICD.display(grp)\n",
    "        \n",
    "    else:\n",
    "        res = \"\"\n",
    "        for o, w in zip(seq, sp.predict_tags_given_words(seq)):\n",
    "            if o not in corpus:                                         ###\n",
    "                correct_o, dist = edit_ditance_word(o, X_train_txt)\n",
    "                if dist <= sensibility:\n",
    "                    seq[seq.index(o)] = correct_o\n",
    "                    w = sp.predict_tags_given_words(seq)[seq.index(correct_o)]\n",
    "                    if change_word:\n",
    "                        o = correct_o\n",
    "            ft = \" {}/{}\" if num2lab[w]=='O' else \" {}/\\x1b[34m{}\\x1b[0m\"\n",
    "            res += ft.format(o, num2lab[w]) \n",
    "        print(res)\n",
    "    \n",
    "    \n",
    "def predict_batch_text_tags(batch, nice_format=False, change_word=False, sensibility=2):\n",
    "    all_s = sum(isinstance(seq, str) for seq in batch)\n",
    "    all_l = sum(isinstance(seq, list) for seq in batch)\n",
    "    assert all_s==0 or all_l==0, \"The inputs must be sentences (string format or lists of words)\"\n",
    "\n",
    "    for b in batch:\n",
    "        predict_text_tags(b, nice_format, change_word, sensibility)\n",
    "        \n",
    "        \n",
    "def word_in_corpus(phrase):\n",
    "    corpus = list(itertools.chain(*X_train_txt)) # Use train words\n",
    "    for i in range(len(phrase)):\n",
    "        if phrase[i] not in corpus:\n",
    "            print(phrase[i])\n",
    "            palabra, dist = edit_ditance_word(phrase[i])\n",
    "            if dist==1:\n",
    "                phrase[i] = palabra\n",
    "    return phrase\n",
    "\n",
    "\n",
    "def edit_ditance_word(mistake, X_train_txt):\n",
    "    # mistake = \"Barchelona\" \n",
    "    corpus = [w for seq in X_train_txt for w in seq]\n",
    "    distances = [editdistance.eval(mistake, word) for word in corpus]\n",
    "    return corpus[np.argmin(distances)], min(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "epochs_before_stopping = 5\n",
    "train_perceptron(load_no_fit=True, num_epochs = num_epochs, epochs_before_stopping = epochs_before_stopping)\n",
    "\n",
    "# evaluate_perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = sp.evaluate_corpus(test_seq_list.seq_list, sp.viterbi_decode_corpus(test_seq_list))\n",
    "print('Checking same Validation Accuracy: %f' % (val_acc))\n",
    "# Checking same Validation Accuracy: 0.560440 with ExtendedFeatures\n",
    "# Checking same Validation Accuracy: 0.955210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_batch_text_tags([\"The programmers from Barcelona might write a sentence without a spell checker .\",\n",
    "\"The programmers from Barchelona cannot write a sentence without a spell checker .\",\n",
    "\"Jack London went to Parrris .\",\n",
    "\"Jack London went to Paris .\",\n",
    "\"We never though Microsoft would become such a big company .\",\n",
    "\"We never though Microsof would become such a big company .\",\n",
    "\"The president of U.S.A though they could win the war\",\n",
    "\"The president of the United States of America though they could win the war\",\n",
    "\"The king of Saudi Arabia wanted total control .\",\n",
    "\"Robin does not want to go to Saudi Arabia .\",\n",
    "\"Apple is a great company .\",\n",
    "\"I really love apples and oranges .\"], nice_format=False, change_word=False, sensibility=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT\n",
    "+ Bidirectional Encoder Representations from Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "\n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[word[0] for word in sentence] for sentence in getter.sentences]\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [[s[2] for s in sentence] for sentence in getter.sentences]\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_values = list(set(data[\"Tag\"].values))\n",
    "tag_values.append(\"PAD\")\n",
    "tag2idx = {t: i for i, t in enumerate(tag_values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 75\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU \n",
    "gpu_id = 3\n",
    "\n",
    "device = torch.device(\"cuda:{}\".format(gpu_id) if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, text_labels):\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    for word, label in zip(sentence, text_labels):\n",
    "\n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts_and_labels = [tokenize_and_preserve_labels(sent, labs) for sent, labs in tqdm(zip(sentences, labels), total=len(sentences))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n",
    "labels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
    "                          truncating=\"post\", padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
    "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
    "                     dtype=\"long\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags,\n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "tr_tags = torch.tensor(tr_tags)\n",
    "val_tags = torch.tensor(val_tags)\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertForTokenClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\n",
    "    \"bert-base-cased\",\n",
    "    num_labels=len(tag2idx),\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False\n",
    ")\n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters())\n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "\n",
    "optimizer = AdamW(\n",
    "    optimizer_grouped_parameters,\n",
    "    lr=3e-5,\n",
    "    eps=1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 3\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store the average loss after each epoch so we can plot them.\n",
    "loss_values, validation_loss_values = [], []\n",
    "\n",
    "for _ in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    model.train()\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Training loop\n",
    "    for step, batch in tqdm(enumerate(train_dataloader), leave=False, total=len(train_dataloader), desc=\"Training\"):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Always clear any previously calculated gradients before performing a backward pass.\n",
    "        model.zero_grad()\n",
    "        # forward pass\n",
    "        # This will return the loss (rather than the model output)\n",
    "        # because we have provided the `labels`.\n",
    "        outputs = model(b_input_ids, token_type_ids=None,\n",
    "                        attention_mask=b_input_mask, labels=b_labels)\n",
    "        # get the loss\n",
    "        loss = outputs[0]\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        total_loss += loss.item()\n",
    "        # Clip the norm of the gradient\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(\"Average train loss: {}\".format(avg_train_loss))\n",
    "\n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    # Put the model into evaluation mode\n",
    "    model.eval()\n",
    "    # Reset the validation loss for this epoch.\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    \n",
    "    for batch in tqdm(valid_dataloader, desc=\"Validation\", leave=False):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Telling the model not to compute or store gradients,\n",
    "        # saving memory and speeding up validation\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have not provided labels.\n",
    "            outputs = model(b_input_ids, token_type_ids=None,\n",
    "                            attention_mask=b_input_mask, labels=b_labels)\n",
    "        # Move logits and labels to CPU\n",
    "        logits = outputs[1].detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        eval_loss += outputs[0].mean().item()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.extend(label_ids)\n",
    "\n",
    "    eval_loss = eval_loss / len(valid_dataloader)\n",
    "    validation_loss_values.append(eval_loss)\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
    "                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
    "    valid_tags = [tag_values[l_i] for l in true_labels\n",
    "                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n",
    "    print(\"Validation Accuracy: {}\".format(accuracy_score(pred_tags, valid_tags)))\n",
    "    print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o', label=\"training loss\")\n",
    "plt.plot(validation_loss_values, 'r-o', label=\"validation loss\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
