{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Pre-existing libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn import *\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "# Custom made modules\n",
    "from SimpleCountVectorizer import *\n",
    "from SimpleCountVectorizerAMC import *\n",
    "from TFIDFVectorizer import *\n",
    "from utils import *\n",
    "from mistakes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/quora_train_data.csv\")\n",
    "test_df = pd.read_csv('./data/quora_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((323432, 6), (80858, 6))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str'}\n"
     ]
    }
   ],
   "source": [
    "all_questions = cast_list_as_strings(list(train_df.loc[:, 'question1'])+list(train_df.loc[:, 'question2']))\n",
    "print(set(type(x).__name__ for x in all_questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Tokenizer function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The tokenization function is the most important function of our CountVectorizer. It is in charge of deciding which tokens will represent a document (or phrase). As we can see, multiple functionalities have been added, which we will detail below:\n",
    "\n",
    "* **Stopwords**: deactivated by default, it removes the most common English words. \n",
    "    This functionality made us reduce the evaluation metrics in that specific problem but it is a good functionality to take into account in future projects.\n",
    "\n",
    "\n",
    "* **Numbers to words**: allows to solve problems like:\n",
    "    * Q1: How much is 2+2?\n",
    "    * Q2: What is the sum of two plus two?\n",
    "    \n",
    "    In this case the numbers are converted to their string representation thanks to a function implemented in the utils library.\n",
    "\n",
    "\n",
    "* **Stemmer and Lemmatizer**: Two great allies of any text model, they serve to standardize the words by converting them to their root word, remove the 's' from the plurals...\n",
    "\n",
    "\n",
    "* **N-grams**: To improve prediction and not use only tokens, we have introduced tuples of tokens. As in sklearn, we can specify the size of the N-grams with a function parameter.\n",
    "\n",
    "* **N-tokens**: We suspected questions that had the same number of tokens would be more likely to have the same meaning. Therefore, we implemented a feature which appended a token to every question corresponding to the question length (i.e. ['How', 'old', 'am', 'I'] --> ['How', 'old', 'am', 'I', 'four_words']). This effectively produces a one-hot-encoding for the number of tokens in each question.\n",
    "\n",
    "\n",
    "\n",
    "* **Duplicate question words**: In order to enhance the type of the question, we duplicate the keyword.\n",
    "\n",
    "* **Duplicate verbs**: Verbs are extremely important in deciphering the underlying meaning of a sentence. Therefore, we built a feature to apply more importance to them via duplication. Though this approach seemed intuitive, it did not actually improve the performance of the classifier and we therefore left this feature disabled by default. \n",
    "\n",
    "* **Duplicate nouns**: Nouns are extremely important in deciphering the underlying meaning of a sentence. Therefore, we attributed more importance to them via duplication.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Simple Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "* **N-tokens**: We added an extra feature when applying transform in SimpleCountVectorizerAMC which encodes the number of tokens in each question. This method differs from the previous implementation in that it only adds a single feature to the sparse matrix. Moreover, it helps the classifier by providing a distance between the lengths of questions. Both N-token's features improved accuracy. \n",
    "\n",
    "* **Out-of-vocabulary words**: After importing several word distances we tried to find the closest word in the vocabulary to each out-of-vocabulary word. \n",
    "Due to both Levenstein and Jaccard distandces having a complexity of $O(N^2)$ and due to the extremely large number of features produced from our simple count vectorizer, the distances' computations proved to be unfeasible. Seeing this, we implemented a naive yet fast distance algorithm which had a complexity upperbound of $O(min(L1, L2))$ where L1 and L2 are the respective lengths of each word.  In the end, this faster approach also proved to be infeasible. Therefore, we didn't include either of these approaches in the final algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Fitting the improved SimpleCountVectorizer\n",
    "+ Now we are loading the sparse matrices directory. The sparse matrices are produced in **F1_Building_the_model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Transforming the datasets into sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((323432, 9425768), (323432, 6), (80858, 9425768), (80858, 6))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_q1q2 = scipy.sparse.load_npz('models/X_tr_q1q2.npz')\n",
    "X_te_q1q2 = scipy.sparse.load_npz('models/X_te_q1q2.npz')\n",
    "\n",
    "## Checking shapes\n",
    "X_tr_q1q2.shape, train_df.shape, X_te_q1q2.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((323432,), (80858,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_df[\"is_duplicate\"].values\n",
    "y_test = test_df['is_duplicate'].values\n",
    "\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Base model (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in training: 0.9990075193549185\n",
      "Accuracy in testing: 0.8131662915234115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=1,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model from disk\n",
    "loaded_linear_reg = pickle.load(open(\"models/model_lr_count.pkl\", 'rb'))\n",
    "result_train = loaded_linear_reg.score(X_tr_q1q2, y_train)\n",
    "result_test = loaded_linear_reg.score(X_te_q1q2, y_test)\n",
    "\n",
    "print(\"Accuracy in training:\", result_train)\n",
    "print(\"Accuracy in testing:\",result_test)\n",
    "loaded_linear_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Improving results (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/xgboost_model_countvect.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d4c09a2794d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxgb_model_countvect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"models/xgboost_model_countvect.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mresult_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_model_countvect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr_q1q2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mresult_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_model_countvect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_te_q1q2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/xgboost_model_countvect.pkl'"
     ]
    }
   ],
   "source": [
    "xgb_model_countvect = pickle.load(open(\"models/xgboost_model_countvect.pkl\", 'rb'))\n",
    "\n",
    "result_train = xgb_model_countvect.score(X_tr_q1q2, y_train)\n",
    "result_test = xgb_model_countvect.score(X_te_q1q2, y_test)\n",
    "\n",
    "print(\"Accuracy in training:\", result_train)\n",
    "print(\"Accuracy in testing:\",result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:26:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.0.0\\src\\learner.cc:979: Number of columns does not match number of features in booster. Columns: 9425768 Features: 6595608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N=10000\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=N)\n",
    "xgb_model.load_model('models/model_tfidf.dat')\n",
    "xgb_model.predict(X_tr_q1q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Some coments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "+ TFIDF vectorizer underperformed with respect to SimpleCountVectorizer in all the attempts performed. We hypothesize that the TFIDF vectors are worse for this specific task and one of the reasons could be that, using TFIDF, the question words (such as what, why, when, who, etc) appear in lots of documents rendering them less important in the TFIDF feature vector. This could very well induce a strong retraction in the performance of any classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
