{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\solej\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\solej\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn import *\n",
    "import re\n",
    "from SimpleCountVectorizer import *\n",
    "from TFIDFVectorizer import *\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Given an int32 number, print it in English.\"\"\"\n",
    "def int_to_en(num):\n",
    "    d = { 0 : 'zero', 1 : 'one', 2 : 'two', 3 : 'three', 4 : 'four', 5 : 'five',\n",
    "          6 : 'six', 7 : 'seven', 8 : 'eight', 9 : 'nine', 10 : 'ten',\n",
    "          11 : 'eleven', 12 : 'twelve', 13 : 'thirteen', 14 : 'fourteen',\n",
    "          15 : 'fifteen', 16 : 'sixteen', 17 : 'seventeen', 18 : 'eighteen',\n",
    "          19 : 'nineteen', 20 : 'twenty',\n",
    "          30 : 'thirty', 40 : 'forty', 50 : 'fifty', 60 : 'sixty',\n",
    "          70 : 'seventy', 80 : 'eighty', 90 : 'ninety' }\n",
    "    k = 1000\n",
    "    m = k * 1000\n",
    "    b = m * 1000\n",
    "    t = b * 1000\n",
    "\n",
    "    assert(0 <= num)\n",
    "\n",
    "    if (num < 20):\n",
    "        return d[num]\n",
    "\n",
    "    if (num < 100):\n",
    "        if num % 10 == 0: return d[num]\n",
    "        else: return d[num // 10 * 10] + '-' + d[num % 10]\n",
    "\n",
    "    if (num < k):\n",
    "        if num % 100 == 0: return d[num // 100] + ' hundred'\n",
    "        else: return d[num // 100] + ' hundred and ' + int_to_en(num % 100)\n",
    "\n",
    "    if (num < m):\n",
    "        if num % k == 0: return int_to_en(num // k) + ' thousand'\n",
    "        else: return int_to_en(num // k) + ' thousand, ' + int_to_en(num % k)\n",
    "\n",
    "    if (num < b):\n",
    "        if (num % m) == 0: return int_to_en(num // m) + ' million'\n",
    "        else: return int_to_en(num // m) + ' million, ' + int_to_en(num % m)\n",
    "\n",
    "    if (num < t):\n",
    "        if (num % b) == 0: return int_to_en(num // b) + ' billion'\n",
    "        else: return int_to_en(num // b) + ' billion, ' + int_to_en(num % b)\n",
    "\n",
    "    if (num % t == 0): return int_to_en(num // t) + ' trillion'\n",
    "    else: return int_to_en(num // t) + ' trillion, ' + int_to_en(num % t)\n",
    "\n",
    "    raise AssertionError('num is too large: %s' % str(num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/quora_train_data.csv\")\n",
    "test_df = pd.read_csv('./data/quora_test_data.csv')\n",
    "\n",
    "# train_df, test_df = sklearn.model_selection.train_test_split(train_df, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((323432, 6), (80858, 6))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_list_as_strings(mylist):\n",
    "    \"\"\"\n",
    "    return a list of strings\n",
    "    \"\"\"\n",
    "    assert isinstance(mylist, list), f\"the input mylist should be a list it is {type(mylist)}\"\n",
    "    \n",
    "    # return list(map(lambda x: str(x), all_questions)) # Slower\n",
    "    return [str(s) for s in mylist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str'}\n"
     ]
    }
   ],
   "source": [
    "all_questions = cast_list_as_strings(list(train_df.loc[:, 'question1'])+list(train_df.loc[:, 'question2']))\n",
    "print(set(type(x).__name__ for x in all_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_conv(s):\n",
    "    try:\n",
    "        return int_to_en(int(s)).replace(\",\",\"\").replace(\" \",\"_\")\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "\n",
    "def my_doc_cleaner(doc,\n",
    "                  pat=r\"[^a-zA-Z0-9]\"):\n",
    "    # Allow alphanumeric characters\n",
    "    doc_cleaner_pattern=pat\n",
    "    clean_doc_pattern = re.compile(doc_cleaner_pattern)\n",
    "    doc_clean = clean_doc_pattern.sub(\" \", doc)\n",
    "    return doc.lower()\n",
    "\n",
    "\n",
    "# stpw = set(stopwords.words(\"english\"))\n",
    "stpw = []\n",
    "\n",
    "stemmer =  SnowballStemmer(language='english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def my_tokenizer_func(doc, \n",
    "                      ngrams=(1,3), \n",
    "                      numbers_to_words=True,\n",
    "                      stop_words=stpw,\n",
    "                      pat=r\"(?u)\\b\\w\\S*\\w*\\b\",\n",
    "                      lem=True,\n",
    "                      stem=True):\n",
    "    \n",
    "    # Split using a patterm\n",
    "#     pat=r\"(?u)\\b\\w\\w+\\b\"\n",
    "#     pat=r\"(?u)\\b\\w\\S*\\w*\\b\"\n",
    "    token_pattern = re.compile(pat)\n",
    "    lst = token_pattern.findall(doc)\n",
    "    \n",
    "    # Transform numbers into words\n",
    "    if numbers_to_words:\n",
    "        lst = list(map(lambda x: num_conv(x), lst))\n",
    "        \n",
    "    # Drop stopwords \n",
    "    lst = list(filter(lambda x : x not in stop_words, lst))\n",
    "    \n",
    "    #Stemmer\n",
    "    if stem:\n",
    "        lst = list(map(lambda x: stemmer.stem(x), lst))\n",
    "    \n",
    "    #Lemmatizer \n",
    "    if lem:\n",
    "        lst = list(map(lambda x: lemmatizer.lemmatize(x), lst))\n",
    "        \n",
    "    if ngrams==(1,1):\n",
    "        return lst\n",
    "    \n",
    "    # Generate ngrams\n",
    "    lstRet = []\n",
    "    for a in range(ngrams[0], ngrams[1]+1):\n",
    "        if a!=1:\n",
    "            lstRet+=list(zip(*[lst[i:] for i in range(a)]))\n",
    "    return lstRet if ngrams[0]!=1 else lst+lstRet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b498f7d9a54b28b39a364ff823a9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=646864), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleCountVectorizer(doc_cleaner_func=<function my_doc_cleaner at 0x00000175E8A45EE8>,\n",
       "                      doc_cleaner_pattern='[^a-zA-Z]',\n",
       "                      dtype=<class 'numpy.float32'>, min_word_counts=1,\n",
       "                      token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                      tokenizer_func=<function my_tokenizer_func at 0x00000175E8A45E58>,\n",
       "                      word_transformer_func=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = SimpleCountVectorizer(\n",
    "    doc_cleaner_func=my_doc_cleaner,\n",
    "    tokenizer_func=my_tokenizer_func\n",
    ")\n",
    "count_vect.fit(all_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_df(df, vectorizer):\n",
    "    \"\"\"\n",
    "    returns a sparse matrix containing the features build by the count vectorizer.\n",
    "    Each row should contain features from question1 and question2.\n",
    "    \"\"\"\n",
    "    q1_casted =  cast_list_as_strings(list(df[\"question1\"]))\n",
    "    q2_casted =  cast_list_as_strings(list(df[\"question2\"]))\n",
    "    \n",
    "    q1 = vectorizer.transform(q1_casted)\n",
    "    q2 = vectorizer.transform(q2_casted)\n",
    "    \n",
    "    X_q1q2 = scipy.sparse.hstack((q1,q2))\n",
    "        \n",
    "    return X_q1q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 11s\n",
      "Wall time: 30.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((323432, 6166022), (323432, 6), (80858, 6166022), (80858, 6))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time X_tr_q1q2 = get_features_from_df(train_df,count_vect)\n",
    "%time X_te_q1q2  = get_features_from_df(test_df, count_vect)\n",
    "\n",
    "X_tr_q1q2.shape, train_df.shape, X_te_q1q2.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[\"is_duplicate\"].values\n",
    "y_test = test_df['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF fit finished in 122.3 seconds\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TFIDFVectorizer(count_vect.vocabulary, count_vect.word_to_ind, count_vect.tokenize)\n",
    "tfidf_vectorizer.fit(all_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF transform finished in 60.67 seconds\n",
      "TFIDF transform finished in 66.51 seconds\n",
      "TFIDF transform finished in 15.17 seconds\n",
      "TFIDF transform finished in 15.39 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((323432, 6166022), (323432, 6), (80858, 6166022), (80858, 6))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf_tr_q1q2 = get_features_from_df(train_df, tfidf_vectorizer)\n",
    "X_tfidf_te_q1q2  = get_features_from_df(test_df, tfidf_vectorizer)\n",
    "\n",
    "X_tfidf_tr_q1q2.shape, train_df.shape, X_tfidf_te_q1q2.shape, test_df.shape,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = sklearn.linear_model.LogisticRegression(solver=\"liblinear\", verbose=1, max_iter=100)\n",
    "logistic.fit(X_tfidf_tr_q1q2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9963670879813995, 0.8085285314996661)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.score(X_tfidf_tr_q1q2, y_train), logistic.score(X_tfidf_te_q1q2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.582471\tvalidation_0-logloss:0.68161\tvalidation_1-auc:0.570312\tvalidation_1-logloss:0.683079\n",
      "Multiple eval metrics have been passed: 'validation_1-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-logloss hasn't improved in 10 rounds.\n",
      "[25]\tvalidation_0-auc:0.724575\tvalidation_0-logloss:0.601594\tvalidation_1-auc:0.659218\tvalidation_1-logloss:0.625644\n",
      "[50]\tvalidation_0-auc:0.746919\tvalidation_0-logloss:0.580876\tvalidation_1-auc:0.684492\tvalidation_1-logloss:0.611773\n",
      "[75]\tvalidation_0-auc:0.759922\tvalidation_0-logloss:0.568224\tvalidation_1-auc:0.701385\tvalidation_1-logloss:0.601904\n",
      "[100]\tvalidation_0-auc:0.769238\tvalidation_0-logloss:0.559079\tvalidation_1-auc:0.712627\tvalidation_1-logloss:0.594734\n",
      "[125]\tvalidation_0-auc:0.775803\tvalidation_0-logloss:0.552316\tvalidation_1-auc:0.72039\tvalidation_1-logloss:0.589766\n",
      "[150]\tvalidation_0-auc:0.781074\tvalidation_0-logloss:0.546884\tvalidation_1-auc:0.726583\tvalidation_1-logloss:0.585312\n",
      "[175]\tvalidation_0-auc:0.785557\tvalidation_0-logloss:0.542266\tvalidation_1-auc:0.732059\tvalidation_1-logloss:0.581661\n",
      "[200]\tvalidation_0-auc:0.789618\tvalidation_0-logloss:0.538266\tvalidation_1-auc:0.736991\tvalidation_1-logloss:0.578338\n",
      "[225]\tvalidation_0-auc:0.793168\tvalidation_0-logloss:0.534394\tvalidation_1-auc:0.741532\tvalidation_1-logloss:0.574962\n",
      "[250]\tvalidation_0-auc:0.796104\tvalidation_0-logloss:0.531005\tvalidation_1-auc:0.744832\tvalidation_1-logloss:0.572283\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-fa53577c359e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m               \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tfidf_tr_q1q2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tfidf_te_q1q2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m               \u001b[0mearly_stopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m               \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'auc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'logloss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m               )\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1109\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "N = 1000 # With early stopping\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=N)\n",
    "xgb_model.fit(X_tfidf_tr_q1q2, y_train, \n",
    "              verbose=25, \n",
    "              eval_set=[(X_tfidf_tr_q1q2, y_train),(X_tfidf_te_q1q2, y_test)], \n",
    "              early_stopping_rounds =10,\n",
    "              eval_metric=['auc','logloss'],\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters = {'nthread':[4], \n",
    "#               'objective':['binary:logistic'],\n",
    "#               'learning_rate': [0.1,0.5,1], \n",
    "#               'max_depth': [3,5],\n",
    "#               'scale_pos_weight':[1,5,20],\n",
    "#               'min_child_weight': [4,5],\n",
    "#               'silent': [1],\n",
    "#               'subsample': [0.7],\n",
    "#               'colsample_bytree': [0.7, 0.9],\n",
    "#               'n_estimators': [50]}\n",
    "\n",
    "# N = 100\n",
    "# xgb_model = xgb.XGBClassifier(n_estimators=N)\n",
    "# grid = GridSearchCV(xgb_model, parameters,\n",
    "#                     n_jobs = 5, scoring='roc_auc',\n",
    "#                     verbose=True)\n",
    "# grid.fit(X_tr_q1q2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mistakes(clf, X_q1q2, y):\n",
    "\n",
    "    predictions = np.around(clf.predict(X_q1q2)).astype(int)   \n",
    "#     print(y[:10])\n",
    "#     print(predictions[:10])\n",
    "    incorrect_predictions = predictions!=y\n",
    "#     print(incorrect_predictions[:10])\n",
    "#     print(np.where(incorrect_predictions)[:10])\n",
    "    incorrect_indices = np.where(incorrect_predictions)[0]\n",
    "    \n",
    "    if np.sum(incorrect_predictions)==0:\n",
    "        print(\"no mistakes in this df\")\n",
    "    else:\n",
    "        return incorrect_indices, predictions\n",
    "    \n",
    "def print_mistake_k(k, mistake_indices, predictions, df):\n",
    "    print(df.iloc[mistake_indices[k]].question1)\n",
    "    print(df.iloc[mistake_indices[k]].question2)\n",
    "    print(\"true class:\", df.iloc[mistake_indices[k]].is_duplicate)\n",
    "    print(\"prediction:\", predictions[mistake_indices[k]])\n",
    "    \n",
    "def print_mistake_k_and_tokens(k, mistake_indices, predictions,\n",
    "                               X_q1q2, count_vect, clf, df):\n",
    "    q1 = df.iloc[mistake_indices[k]].question1\n",
    "    q2 = df.iloc[mistake_indices[k]].question2\n",
    "    \n",
    "    print(q1)\n",
    "    print(count_vect.tokenize(q1))\n",
    "    print()\n",
    "    print(q2)\n",
    "    print(count_vect.tokenize(q2))\n",
    "    print()\n",
    "    print(\"true class:\", df.iloc[mistake_indices[k]].is_duplicate)\n",
    "    print(\"prediction:\", predictions[mistake_indices[k]])\n",
    "    print()\n",
    "    print(\"Probability vector: [P(0|x), P(1|x)]:\")\n",
    "    print(clf.predict_proba(X_q1q2)[mistake_indices[k],:])\n",
    "    \n",
    "    \n",
    "def hist_errors(mistake_indices, predictions,\n",
    "                               X_q1q2, count_vect, clf, df):\n",
    "    qs = df.iloc[mistake_indices][['question1', 'question2']]\n",
    "    qs['true_class']=df.iloc[mistake_indices].is_duplicate\n",
    "    qs['prediction']=predictions[mistake_indices]\n",
    "    qs['P(1|x)']=clf.predict_proba(X_q1q2)[mistake_indices,:][:,1]\n",
    "    qs = qs.reset_index(drop=True)\n",
    "    return qs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistake_indices, predictions = get_mistakes(xgb_model, X_te_q1q2, y_test, df=test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.save_model('models/xgb_2825its_0.88763auc_0.40673logloss.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xgboost.core.Booster object at 0x00000175DD4DA308>\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.Booster({'nthread': 4})  # init booster\n",
    "bst.load_model('models/xgb_2825its_0.88763auc_0.40673logloss.dat')  # load data\n",
    "print(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_loaded_model = xgb.XGBClassifier()\n",
    "xgb_loaded_model._Booster = bst\n",
    "xgb_loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Booster' object has no attribute 'evals_result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a4405448ebf3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_loaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'validation_0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logloss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mx_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'evals_result'"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "results = xgb_loaded_model._Booster.evals_result()\n",
    "epochs = len(results['validation_0']['logloss'])\n",
    "x_axis = range(0, epochs)\n",
    "\n",
    "fig = plt.figure(figsize=(20,6))\n",
    "\n",
    "# plot log loss\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "ax.legend()\n",
    "ax.set_ylabel('Log Loss')\n",
    "ax.set_title('XGBoost Log Loss')\n",
    "\n",
    "# plot classification AUC\n",
    "ax = fig.add_subplot(122)\n",
    "ax.plot(x_axis, results['validation_0']['auc'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['auc'], label='Test')\n",
    "ax.legend()\n",
    "ax.set_ylabel('Classification AUC')\n",
    "ax.set_title('XGBoost Classification AUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistake_indices, predictions = get_mistakes(xgb_loaded_model, X_te_q1q2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15342"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mistake_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which book is the best for GRE preparation?\n",
      "Which are the best books for the IELTS and the GRE preparation?\n",
      "true class: 0\n",
      "prediction: 1\n"
     ]
    }
   ],
   "source": [
    "print_mistake_k(0, mistake_indices, predictions, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which book is the best for GRE preparation?\n",
      "['which', 'book', 'is', 'the', 'best', 'for', 'gre', 'prepar', ('which', 'book'), ('book', 'is'), ('is', 'the'), ('the', 'best'), ('best', 'for'), ('for', 'gre'), ('gre', 'prepar'), ('which', 'book', 'is'), ('book', 'is', 'the'), ('is', 'the', 'best'), ('the', 'best', 'for'), ('best', 'for', 'gre'), ('for', 'gre', 'prepar')]\n",
      "\n",
      "Which are the best books for the IELTS and the GRE preparation?\n",
      "['which', 'are', 'the', 'best', 'book', 'for', 'the', 'ielt', 'and', 'the', 'gre', 'prepar', ('which', 'are'), ('are', 'the'), ('the', 'best'), ('best', 'book'), ('book', 'for'), ('for', 'the'), ('the', 'ielt'), ('ielt', 'and'), ('and', 'the'), ('the', 'gre'), ('gre', 'prepar'), ('which', 'are', 'the'), ('are', 'the', 'best'), ('the', 'best', 'book'), ('best', 'book', 'for'), ('book', 'for', 'the'), ('for', 'the', 'ielt'), ('the', 'ielt', 'and'), ('ielt', 'and', 'the'), ('and', 'the', 'gre'), ('the', 'gre', 'prepar')]\n",
      "\n",
      "true class: 0\n",
      "prediction: 1\n",
      "\n",
      "Probability vector: [P(0|x), P(1|x)]:\n",
      "[0.3183987 0.6816013]\n"
     ]
    }
   ],
   "source": [
    "print_mistake_k_and_tokens(0, mistake_indices, predictions,\n",
    "                           X_te_q1q2, count_vect, xgb_loaded_model, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = hist_errors(mistake_indices, predictions,\n",
    "                           X_te_q1q2, count_vect, xgb_loaded_model, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 50\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_rows', N)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>true_class</th>\n",
       "      <th>prediction</th>\n",
       "      <th>P(1|x)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which book is the best for GRE preparation?</td>\n",
       "      <td>Which are the best books for the IELTS and the GRE preparation?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.681601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can an Indian student get into Harvard Medical School for their undergrad?</td>\n",
       "      <td>What do I need to do to get into Harvard Medical School?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.652885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the purpose of solubility tests?</td>\n",
       "      <td>Why do you do the solubility test?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I getting my period so much?</td>\n",
       "      <td>Why am I getting my period twice a month?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can I recover an iPhone 5 deleted text conversation?</td>\n",
       "      <td>How do I retrieve my deleted SMS from iPhone 6?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.274019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Is there any way to adjust title and font default settings in Google docs?</td>\n",
       "      <td>How can I change the default font in Google docs?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.087301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How many articles does the Constitution have?</td>\n",
       "      <td>How many articles and chapter are their in our Indian constitution?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can I prepare for a technical and hr interview?</td>\n",
       "      <td>How do I prepare for my hr interview?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.457206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Is LinkedIn a good acquisition for Microsoft?</td>\n",
       "      <td>Will Microsoft's acquisition of LinkedIn prove useful for Microsoft? If so, what will 'useful' look like?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.306823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Does Hillary Clinton have any serious health issues?</td>\n",
       "      <td>Does Hillary Clinton have any known health issues that might keep her from running or succeeding in 2016?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.449223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What is a limbo?</td>\n",
       "      <td>What is actually a limbo?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.443144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How can one get a patent?</td>\n",
       "      <td>Can I get patent for a simple idea?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.618264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What business can I start that wonâ€™t require my presence to operate?</td>\n",
       "      <td>What can I do to support and encourage the development of synthetic meat?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.554533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Is it safe for a woman to travel alone in Vietnam?</td>\n",
       "      <td>Is it safe for a woman to travel alone in Japan?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What should I learn before joining CA articleship?</td>\n",
       "      <td>What skills should a CA student develop before starting articleship?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What is the life of an IES officer?</td>\n",
       "      <td>What is the lifestyle of an IAS officer?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.381431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What hobby or pass time are you passionate about?</td>\n",
       "      <td>What are your hobbies? What are you passionate about?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What are some ways to lace etnies shoes?</td>\n",
       "      <td>What are some ways to lace your shoes?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.560160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I am final year Engineering student and I want to prepare for IBPS PO 2016. How do I start preparation?</td>\n",
       "      <td>How can I prepare for IBPS PO 2016 from scratch?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How do you cure premature ejaculation?</td>\n",
       "      <td>How do I stop premature ejaculation?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.434164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>When and why should I write a book about myself?</td>\n",
       "      <td>Why should you write a book?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I want to reduce my belly fat. I'm completely new to exercise kind of stuff. Can you suggest some good websites or Android apps to learn how to exercise?</td>\n",
       "      <td>How do I get rid of lower belly pouch, suggest some diet &amp; exercise?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>How is Smirnoff vodka made, and how does this process compare to the one used for Absolute vodka?</td>\n",
       "      <td>How is Smirnoff vodka made?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.059265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Which are the best Christmas movies of all time?</td>\n",
       "      <td>Where is the best place to go skiing at Christmas time?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.663890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Is it possible to arbitrage the different onshore and offshore Renminbi rates?</td>\n",
       "      <td>Why does the domestic and offshore Renminbi have different values? Why can't they converge?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.194974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What do you think about kids nowadays?</td>\n",
       "      <td>What do you think of kids these days?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.447428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>How should I apply for a domicile certificate in Thane?</td>\n",
       "      <td>How do I apply for domicile certificate in Thane?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.347334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>How do I send a picture/message from Facebook to WhatsApp?</td>\n",
       "      <td>How do I send text message from Facebook to WhatsApp?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.577177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What is the wholesale market price (i.e per kg) of sitagliptine phosphate, candesarten cilexetil, modafinil, lercanidipine HCL, clinidipine?</td>\n",
       "      <td>What are the wholesale market prices (i.e per kg) of sitagliptine phosphate, candesarten cilexitil, modafinil, lercanidipine HCL, and clinidipine?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.274992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>How can I increase my online store sale?</td>\n",
       "      <td>How can I improve my online store sale?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.695271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>What are the best apps for learning new language?</td>\n",
       "      <td>Which app is the best app to learn new languages?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.779682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Why cricket is overrated in India?</td>\n",
       "      <td>Who is the most overrated cricketer in India and why?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.782919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Where do I locate the model number on my Dell laptop?</td>\n",
       "      <td>How can I locate the model number on a Dell laptop?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>What piece of advice would you give to a 12thee for the month of october? You can share your school days and experiences as well.</td>\n",
       "      <td>What piece of advice would you give to a 12thee in the month of october? You can share your school days and experiences as well.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.339935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Where and how were the Montecito Casino scenes filmed?</td>\n",
       "      <td>What were the filming locations of The Schindler list?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>How do you find out if someone has more than one Facebook account?</td>\n",
       "      <td>Is there a way to find out if someone has another Facebook account?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.431701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>What are the differences between Android and iOS?</td>\n",
       "      <td>How different are Android and iOS?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.334485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>How do I socialize without money?</td>\n",
       "      <td>How can one have fun without money?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.776239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Which are the best books to learn HTML, CSS and JavaScript?</td>\n",
       "      <td>What are the best books for learning CSS, JavaScript and PHP?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.578276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Which industry/ sector will benefit the most after the GST bill is passed?</td>\n",
       "      <td>How corporates be benefited by GST?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.611326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>What is devolution? What are the benefits?</td>\n",
       "      <td>What is devolution?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Does the United States ever plan on paying their debt back?</td>\n",
       "      <td>Will the United States ever become debt free?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.207349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>How old were you when you got your first bj?</td>\n",
       "      <td>How old were you when you gave your first blowjob?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>What are the basic questions asked in a job interview?</td>\n",
       "      <td>What are the common questions asked during interviews?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.377698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>What are the perfect Halloween movies?</td>\n",
       "      <td>What are your 3 favorite Halloween movies?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>How earn second income?</td>\n",
       "      <td>What is the best way to get second income?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Are stereotypes actually true?</td>\n",
       "      <td>Which stereotypes are true?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>What do you think about the effect of demonetization?</td>\n",
       "      <td>What will be the effect of demonetization?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>What is it like to work at a casino?</td>\n",
       "      <td>What is it like to work in a casino?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>What are job opportunities after completing one year of a HAL graduate apprenticeship?</td>\n",
       "      <td>What are some opportunities after completing one year of a HAL graduate apprenticeship?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.443865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                    question1                                                                                                                                           question2  true_class  prediction    P(1|x)\n",
       "0   Which book is the best for GRE preparation?                                                                                                                Which are the best books for the IELTS and the GRE preparation?                                                                                     0           1           0.681601\n",
       "1   How can an Indian student get into Harvard Medical School for their undergrad?                                                                             What do I need to do to get into Harvard Medical School?                                                                                            0           1           0.652885\n",
       "2   What is the purpose of solubility tests?                                                                                                                   Why do you do the solubility test?                                                                                                                  1           0           0.028398\n",
       "3   Why am I getting my period so much?                                                                                                                        Why am I getting my period twice a month?                                                                                                           0           1           0.532057\n",
       "4   How can I recover an iPhone 5 deleted text conversation?                                                                                                   How do I retrieve my deleted SMS from iPhone 6?                                                                                                     1           0           0.274019\n",
       "5   Is there any way to adjust title and font default settings in Google docs?                                                                                 How can I change the default font in Google docs?                                                                                                   1           0           0.087301\n",
       "6   How many articles does the Constitution have?                                                                                                              How many articles and chapter are their in our Indian constitution?                                                                                 1           0           0.148157\n",
       "7   How can I prepare for a technical and hr interview?                                                                                                        How do I prepare for my hr interview?                                                                                                               1           0           0.457206\n",
       "8   Is LinkedIn a good acquisition for Microsoft?                                                                                                              Will Microsoft's acquisition of LinkedIn prove useful for Microsoft? If so, what will 'useful' look like?                                           1           0           0.306823\n",
       "9   Does Hillary Clinton have any serious health issues?                                                                                                       Does Hillary Clinton have any known health issues that might keep her from running or succeeding in 2016?                                           1           0           0.449223\n",
       "10  What is a limbo?                                                                                                                                           What is actually a limbo?                                                                                                                           1           0           0.443144\n",
       "11  How can one get a patent?                                                                                                                                  Can I get patent for a simple idea?                                                                                                                 0           1           0.618264\n",
       "12  What business can I start that wonâ€™t require my presence to operate?                                                                                       What can I do to support and encourage the development of synthetic meat?                                                                           0           1           0.554533\n",
       "13  Is it safe for a woman to travel alone in Vietnam?                                                                                                         Is it safe for a woman to travel alone in Japan?                                                                                                    0           1           0.526570\n",
       "14  What should I learn before joining CA articleship?                                                                                                         What skills should a CA student develop before starting articleship?                                                                                1           0           0.380892\n",
       "15  What is the life of an IES officer?                                                                                                                        What is the lifestyle of an IAS officer?                                                                                                            1           0           0.381431\n",
       "16  What hobby or pass time are you passionate about?                                                                                                          What are your hobbies? What are you passionate about?                                                                                               1           0           0.478894\n",
       "17  What are some ways to lace etnies shoes?                                                                                                                   What are some ways to lace your shoes?                                                                                                              0           1           0.560160\n",
       "18  I am final year Engineering student and I want to prepare for IBPS PO 2016. How do I start preparation?                                                    How can I prepare for IBPS PO 2016 from scratch?                                                                                                    0           1           0.706473\n",
       "19  How do you cure premature ejaculation?                                                                                                                     How do I stop premature ejaculation?                                                                                                                1           0           0.434164\n",
       "20  When and why should I write a book about myself?                                                                                                           Why should you write a book?                                                                                                                        0           1           0.887891\n",
       "21  I want to reduce my belly fat. I'm completely new to exercise kind of stuff. Can you suggest some good websites or Android apps to learn how to exercise?  How do I get rid of lower belly pouch, suggest some diet & exercise?                                                                                0           1           0.770697\n",
       "22  How is Smirnoff vodka made, and how does this process compare to the one used for Absolute vodka?                                                          How is Smirnoff vodka made?                                                                                                                         1           0           0.059265\n",
       "23  Which are the best Christmas movies of all time?                                                                                                           Where is the best place to go skiing at Christmas time?                                                                                             0           1           0.663890\n",
       "24  Is it possible to arbitrage the different onshore and offshore Renminbi rates?                                                                             Why does the domestic and offshore Renminbi have different values? Why can't they converge?                                                         1           0           0.194974\n",
       "25  What do you think about kids nowadays?                                                                                                                     What do you think of kids these days?                                                                                                               1           0           0.447428\n",
       "26  How should I apply for a domicile certificate in Thane?                                                                                                    How do I apply for domicile certificate in Thane?                                                                                                   1           0           0.347334\n",
       "27  How do I send a picture/message from Facebook to WhatsApp?                                                                                                 How do I send text message from Facebook to WhatsApp?                                                                                               0           1           0.577177\n",
       "28  What is the wholesale market price (i.e per kg) of sitagliptine phosphate, candesarten cilexetil, modafinil, lercanidipine HCL, clinidipine?               What are the wholesale market prices (i.e per kg) of sitagliptine phosphate, candesarten cilexitil, modafinil, lercanidipine HCL, and clinidipine?  1           0           0.274992\n",
       "29  How can I increase my online store sale?                                                                                                                   How can I improve my online store sale?                                                                                                             0           1           0.695271\n",
       "30  What are the best apps for learning new language?                                                                                                          Which app is the best app to learn new languages?                                                                                                   0           1           0.779682\n",
       "31  Why cricket is overrated in India?                                                                                                                         Who is the most overrated cricketer in India and why?                                                                                               0           1           0.782919\n",
       "32  Where do I locate the model number on my Dell laptop?                                                                                                      How can I locate the model number on a Dell laptop?                                                                                                 1           0           0.375898\n",
       "33  What piece of advice would you give to a 12thee for the month of october? You can share your school days and experiences as well.                          What piece of advice would you give to a 12thee in the month of october? You can share your school days and experiences as well.                    1           0           0.339935\n",
       "34  Where and how were the Montecito Casino scenes filmed?                                                                                                     What were the filming locations of The Schindler list?                                                                                              0           1           0.727444\n",
       "35  How do you find out if someone has more than one Facebook account?                                                                                         Is there a way to find out if someone has another Facebook account?                                                                                 1           0           0.431701\n",
       "36  What are the differences between Android and iOS?                                                                                                          How different are Android and iOS?                                                                                                                  1           0           0.334485\n",
       "37  How do I socialize without money?                                                                                                                          How can one have fun without money?                                                                                                                 0           1           0.776239\n",
       "38  Which are the best books to learn HTML, CSS and JavaScript?                                                                                                What are the best books for learning CSS, JavaScript and PHP?                                                                                       0           1           0.578276\n",
       "39  Which industry/ sector will benefit the most after the GST bill is passed?                                                                                 How corporates be benefited by GST?                                                                                                                 0           1           0.611326\n",
       "40  What is devolution? What are the benefits?                                                                                                                 What is devolution?                                                                                                                                 1           0           0.478930\n",
       "41  Does the United States ever plan on paying their debt back?                                                                                                Will the United States ever become debt free?                                                                                                       1           0           0.207349\n",
       "42  How old were you when you got your first bj?                                                                                                               How old were you when you gave your first blowjob?                                                                                                  0           1           0.563979\n",
       "43  What are the basic questions asked in a job interview?                                                                                                     What are the common questions asked during interviews?                                                                                              1           0           0.377698\n",
       "44  What are the perfect Halloween movies?                                                                                                                     What are your 3 favorite Halloween movies?                                                                                                          1           0           0.499257\n",
       "45  How earn second income?                                                                                                                                    What is the best way to get second income?                                                                                                          1           0           0.406590\n",
       "46  Are stereotypes actually true?                                                                                                                             Which stereotypes are true?                                                                                                                         0           1           0.550901\n",
       "47  What do you think about the effect of demonetization?                                                                                                      What will be the effect of demonetization?                                                                                                          0           1           0.562355\n",
       "48  What is it like to work at a casino?                                                                                                                       What is it like to work in a casino?                                                                                                                1           0           0.128722\n",
       "49  What are job opportunities after completing one year of a HAL graduate apprenticeship?                                                                     What are some opportunities after completing one year of a HAL graduate apprenticeship?                                                             1           0           0.443865"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read mistakes\n",
    "qs = pd.read_csv(\"mistakes.csv\")\n",
    "qs.head(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF fit finished in 181.48 seconds\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TFIDFVectorizer(count_vect.vocabulary, count_vect.word_to_ind, count_vect.tokenize)\n",
    "tfidf_vectorizer.fit(all_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF transform finished in 91.75 seconds\n",
      "TFIDF transform finished in 93.02 seconds\n",
      "TFIDF transform finished in 22.81 seconds\n",
      "TFIDF transform finished in 23.93 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((323432, 6166022), (323432, 6), (80858, 6), (80858, 6166022))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf_tr_q1q2 = get_features_from_df(train_df, tfidf_vectorizer)\n",
    "X_tfidf_te_q1q2  = get_features_from_df(test_df, tfidf_vectorizer)\n",
    "\n",
    "X_tfidf_tr_q1q2.shape, train_df.shape, test_df.shape, X_tfidf_te_q1q2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=1,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = sklearn.linear_model.LogisticRegression(solver=\"liblinear\", verbose=1, max_iter=100)\n",
    "logistic.fit(X_tfidf_tr_q1q2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9006499047713276, 0.7898167157238616)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.score(X_tfidf_tr_q1q2, y_train), logistic.score(X_tfidf_te_q1q2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistake_indices, predictions = get_mistakes(logistic, X_tfidf_te_q1q2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do I study for Honeywell company recruitment?\n",
      "How do I study for Honeywell company recruitments?\n",
      "true class: 1\n",
      "prediction: 0\n"
     ]
    }
   ],
   "source": [
    "print_mistake_k(0, mistake_indices, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do I study for Honeywell company recruitment?\n",
      "['how', 'do', 'i', 'studi', 'for', 'honeywel', 'compani', 'recruit', ('how', 'do'), ('do', 'i'), ('i', 'studi'), ('studi', 'for'), ('for', 'honeywel'), ('honeywel', 'compani'), ('compani', 'recruit'), ('how', 'do', 'i'), ('do', 'i', 'studi'), ('i', 'studi', 'for'), ('studi', 'for', 'honeywel'), ('for', 'honeywel', 'compani'), ('honeywel', 'compani', 'recruit')]\n",
      "\n",
      "How do I study for Honeywell company recruitments?\n",
      "['how', 'do', 'i', 'studi', 'for', 'honeywel', 'compani', 'recruit', ('how', 'do'), ('do', 'i'), ('i', 'studi'), ('studi', 'for'), ('for', 'honeywel'), ('honeywel', 'compani'), ('compani', 'recruit'), ('how', 'do', 'i'), ('do', 'i', 'studi'), ('i', 'studi', 'for'), ('studi', 'for', 'honeywel'), ('for', 'honeywel', 'compani'), ('honeywel', 'compani', 'recruit')]\n",
      "\n",
      "true class: 1\n",
      "prediction: 0\n",
      "\n",
      "Probability vector: [P(0|x), P(1|x)]:\n",
      "[0.73466044 0.26533956]\n"
     ]
    }
   ],
   "source": [
    "print_mistake_k_and_tokens(0, mistake_indices, predictions,\n",
    "                           X_tfidf_te_q1q2, tfidf_vectorizer, logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n",
      "22000\n",
      "22500\n",
      "23000\n",
      "23500\n",
      "24000\n",
      "24500\n",
      "25000\n",
      "25500\n",
      "26000\n",
      "26500\n",
      "27000\n",
      "27500\n",
      "28000\n",
      "28500\n",
      "29000\n",
      "29500\n",
      "30000\n",
      "30500\n",
      "31000\n",
      "31500\n",
      "32000\n",
      "32500\n",
      "33000\n",
      "33500\n",
      "34000\n",
      "34500\n",
      "35000\n",
      "35500\n",
      "36000\n",
      "36500\n",
      "37000\n",
      "37500\n",
      "38000\n",
      "38500\n",
      "39000\n",
      "39500\n",
      "40000\n",
      "40500\n",
      "41000\n",
      "41500\n",
      "42000\n",
      "42500\n",
      "43000\n",
      "43500\n",
      "44000\n",
      "44500\n",
      "45000\n",
      "45500\n",
      "46000\n",
      "46500\n",
      "47000\n",
      "47500\n",
      "48000\n",
      "48500\n",
      "49000\n",
      "49500\n",
      "50000\n",
      "50500\n",
      "51000\n",
      "51500\n",
      "52000\n",
      "52500\n",
      "53000\n",
      "53500\n",
      "54000\n",
      "54500\n",
      "55000\n",
      "55500\n",
      "56000\n",
      "56500\n",
      "57000\n",
      "57500\n",
      "58000\n",
      "58500\n",
      "59000\n",
      "59500\n",
      "60000\n",
      "60500\n",
      "61000\n",
      "61500\n",
      "62000\n",
      "62500\n",
      "63000\n",
      "63500\n",
      "64000\n",
      "64500\n",
      "65000\n",
      "65500\n",
      "66000\n",
      "66500\n",
      "67000\n",
      "67500\n",
      "68000\n",
      "68500\n",
      "69000\n",
      "69500\n",
      "70000\n",
      "70500\n",
      "71000\n",
      "71500\n",
      "72000\n",
      "72500\n",
      "73000\n",
      "73500\n",
      "74000\n",
      "74500\n",
      "75000\n",
      "75500\n",
      "76000\n",
      "76500\n",
      "77000\n",
      "77500\n",
      "78000\n",
      "78500\n",
      "79000\n",
      "79500\n",
      "80000\n",
      "80500\n",
      "81000\n",
      "81500\n",
      "82000\n",
      "82500\n",
      "83000\n",
      "83500\n",
      "84000\n",
      "84500\n",
      "85000\n",
      "85500\n",
      "86000\n",
      "86500\n",
      "87000\n",
      "87500\n",
      "88000\n",
      "88500\n",
      "89000\n",
      "89500\n",
      "90000\n",
      "90500\n",
      "91000\n",
      "91500\n",
      "92000\n",
      "92500\n",
      "93000\n",
      "93500\n",
      "94000\n",
      "94500\n",
      "95000\n",
      "95500\n",
      "96000\n",
      "96500\n",
      "97000\n",
      "97500\n",
      "98000\n",
      "98500\n",
      "99000\n",
      "99500\n",
      "100000\n",
      "100500\n",
      "101000\n",
      "101500\n",
      "102000\n",
      "102500\n",
      "103000\n",
      "103500\n",
      "104000\n",
      "104500\n",
      "105000\n",
      "105500\n",
      "106000\n",
      "106500\n",
      "107000\n",
      "107500\n",
      "108000\n",
      "108500\n",
      "109000\n",
      "109500\n",
      "110000\n",
      "110500\n",
      "111000\n",
      "111500\n",
      "112000\n",
      "112500\n",
      "113000\n",
      "113500\n",
      "114000\n",
      "114500\n",
      "115000\n",
      "115500\n",
      "116000\n",
      "116500\n",
      "117000\n",
      "117500\n",
      "118000\n",
      "118500\n",
      "119000\n",
      "119500\n",
      "120000\n",
      "120500\n",
      "121000\n",
      "121500\n",
      "122000\n",
      "122500\n",
      "123000\n",
      "123500\n",
      "124000\n",
      "124500\n",
      "125000\n",
      "125500\n",
      "126000\n",
      "126500\n",
      "127000\n",
      "127500\n",
      "128000\n",
      "128500\n",
      "129000\n",
      "129500\n",
      "130000\n",
      "130500\n",
      "131000\n",
      "131500\n",
      "132000\n",
      "132500\n",
      "133000\n",
      "133500\n",
      "134000\n",
      "134500\n",
      "135000\n",
      "135500\n",
      "136000\n",
      "136500\n",
      "137000\n",
      "137500\n",
      "138000\n",
      "138500\n",
      "139000\n",
      "139500\n",
      "140000\n",
      "140500\n",
      "141000\n",
      "141500\n",
      "142000\n",
      "142500\n",
      "143000\n",
      "143500\n",
      "144000\n",
      "144500\n",
      "145000\n",
      "145500\n",
      "146000\n",
      "146500\n",
      "147000\n",
      "147500\n",
      "148000\n",
      "148500\n",
      "149000\n",
      "149500\n",
      "150000\n",
      "150500\n",
      "151000\n",
      "151500\n",
      "152000\n",
      "152500\n",
      "153000\n",
      "153500\n",
      "154000\n",
      "154500\n",
      "155000\n",
      "155500\n",
      "156000\n",
      "156500\n",
      "157000\n",
      "157500\n",
      "158000\n",
      "158500\n",
      "159000\n",
      "159500\n",
      "160000\n",
      "160500\n",
      "161000\n",
      "161500\n",
      "162000\n",
      "162500\n",
      "163000\n",
      "163500\n",
      "164000\n",
      "164500\n",
      "165000\n",
      "165500\n",
      "166000\n",
      "166500\n",
      "167000\n",
      "167500\n",
      "168000\n",
      "168500\n",
      "169000\n",
      "169500\n",
      "170000\n",
      "170500\n",
      "171000\n",
      "171500\n",
      "172000\n",
      "172500\n",
      "173000\n",
      "173500\n",
      "174000\n",
      "174500\n",
      "175000\n",
      "175500\n",
      "176000\n",
      "176500\n",
      "177000\n",
      "177500\n",
      "178000\n",
      "178500\n",
      "179000\n",
      "179500\n",
      "180000\n",
      "180500\n",
      "181000\n",
      "181500\n",
      "182000\n",
      "182500\n",
      "183000\n",
      "183500\n",
      "184000\n",
      "184500\n",
      "185000\n",
      "185500\n",
      "186000\n",
      "186500\n",
      "187000\n",
      "187500\n",
      "188000\n",
      "188500\n",
      "189000\n",
      "189500\n",
      "190000\n",
      "190500\n",
      "191000\n",
      "191500\n",
      "192000\n",
      "192500\n",
      "193000\n",
      "193500\n",
      "194000\n",
      "194500\n",
      "195000\n",
      "195500\n",
      "196000\n",
      "196500\n",
      "197000\n",
      "197500\n",
      "198000\n",
      "198500\n",
      "199000\n",
      "199500\n",
      "200000\n",
      "200500\n",
      "201000\n",
      "201500\n",
      "202000\n",
      "202500\n",
      "203000\n",
      "203500\n",
      "204000\n",
      "204500\n",
      "205000\n",
      "205500\n",
      "206000\n",
      "206500\n",
      "207000\n",
      "207500\n",
      "208000\n",
      "208500\n",
      "209000\n",
      "209500\n",
      "210000\n",
      "210500\n",
      "211000\n",
      "211500\n",
      "212000\n",
      "212500\n",
      "213000\n",
      "213500\n",
      "214000\n",
      "214500\n",
      "215000\n",
      "215500\n",
      "216000\n",
      "216500\n",
      "217000\n",
      "217500\n",
      "218000\n",
      "218500\n",
      "219000\n",
      "219500\n",
      "220000\n",
      "220500\n",
      "221000\n",
      "221500\n",
      "222000\n",
      "222500\n",
      "223000\n",
      "223500\n",
      "224000\n",
      "224500\n",
      "225000\n",
      "225500\n",
      "226000\n",
      "226500\n",
      "227000\n",
      "227500\n",
      "228000\n",
      "228500\n",
      "229000\n",
      "229500\n",
      "230000\n",
      "230500\n",
      "231000\n",
      "231500\n",
      "232000\n",
      "232500\n",
      "233000\n",
      "233500\n",
      "234000\n",
      "234500\n",
      "235000\n",
      "235500\n",
      "236000\n",
      "236500\n",
      "237000\n",
      "237500\n",
      "238000\n",
      "238500\n",
      "239000\n",
      "239500\n",
      "240000\n",
      "240500\n",
      "241000\n",
      "241500\n",
      "242000\n",
      "242500\n",
      "243000\n",
      "243500\n",
      "244000\n",
      "244500\n",
      "245000\n",
      "245500\n",
      "246000\n",
      "246500\n",
      "247000\n",
      "247500\n",
      "248000\n",
      "248500\n",
      "249000\n",
      "249500\n",
      "250000\n",
      "250500\n",
      "251000\n",
      "251500\n",
      "252000\n",
      "252500\n",
      "253000\n",
      "253500\n",
      "254000\n",
      "254500\n",
      "255000\n",
      "255500\n",
      "256000\n",
      "256500\n",
      "257000\n",
      "257500\n",
      "258000\n",
      "258500\n",
      "259000\n",
      "259500\n",
      "260000\n",
      "260500\n",
      "261000\n",
      "261500\n",
      "262000\n",
      "262500\n",
      "263000\n",
      "263500\n",
      "264000\n",
      "264500\n",
      "265000\n",
      "265500\n",
      "266000\n",
      "266500\n",
      "267000\n",
      "267500\n",
      "268000\n",
      "268500\n",
      "269000\n",
      "269500\n",
      "270000\n",
      "270500\n",
      "271000\n",
      "271500\n",
      "272000\n",
      "272500\n",
      "273000\n",
      "273500\n",
      "274000\n",
      "274500\n",
      "275000\n",
      "275500\n",
      "276000\n",
      "276500\n",
      "277000\n",
      "277500\n",
      "278000\n",
      "278500\n",
      "279000\n",
      "279500\n",
      "280000\n",
      "280500\n",
      "281000\n",
      "281500\n",
      "282000\n",
      "282500\n",
      "283000\n",
      "283500\n",
      "284000\n",
      "284500\n",
      "285000\n",
      "285500\n",
      "286000\n",
      "286500\n",
      "287000\n",
      "287500\n",
      "288000\n",
      "288500\n",
      "289000\n",
      "289500\n",
      "290000\n",
      "290500\n",
      "291000\n",
      "291500\n",
      "292000\n",
      "292500\n",
      "293000\n",
      "293500\n",
      "294000\n",
      "294500\n",
      "295000\n",
      "295500\n",
      "296000\n",
      "296500\n",
      "297000\n",
      "297500\n",
      "298000\n",
      "298500\n",
      "299000\n",
      "299500\n",
      "300000\n",
      "300500\n",
      "301000\n",
      "301500\n",
      "302000\n",
      "302500\n",
      "303000\n",
      "303500\n",
      "304000\n",
      "304500\n",
      "305000\n",
      "305500\n",
      "306000\n",
      "306500\n",
      "307000\n",
      "307500\n",
      "308000\n",
      "308500\n",
      "309000\n",
      "309500\n",
      "310000\n",
      "310500\n",
      "311000\n",
      "311500\n",
      "312000\n",
      "312500\n",
      "313000\n",
      "313500\n",
      "314000\n",
      "314500\n",
      "315000\n",
      "315500\n",
      "316000\n",
      "316500\n",
      "317000\n",
      "317500\n",
      "318000\n",
      "318500\n",
      "319000\n",
      "319500\n",
      "320000\n",
      "320500\n",
      "321000\n",
      "321500\n",
      "322000\n",
      "322500\n",
      "323000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>3148</td>\n",
       "      <td>6241</td>\n",
       "      <td>6242</td>\n",
       "      <td>How do I overcome my inferiority complex ?</td>\n",
       "      <td>How do I overcome my inferiority complex?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>15678</td>\n",
       "      <td>29935</td>\n",
       "      <td>29936</td>\n",
       "      <td>How can I make money as a 13 year old?</td>\n",
       "      <td>How can I make money as a thirteen year old?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>403514</td>\n",
       "      <td>253677</td>\n",
       "      <td>537096</td>\n",
       "      <td>What are the most haunted places in delhi?</td>\n",
       "      <td>What are the most haunted place in delhi?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>290549</td>\n",
       "      <td>26661</td>\n",
       "      <td>70364</td>\n",
       "      <td>What language is used in Visual Basic? How doe...</td>\n",
       "      <td>What language is used in Visual Basic? How doe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>184520</td>\n",
       "      <td>281899</td>\n",
       "      <td>281900</td>\n",
       "      <td>What are the best things about modeling?</td>\n",
       "      <td>What are the best things about models?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316104</th>\n",
       "      <td>45535</td>\n",
       "      <td>81584</td>\n",
       "      <td>81585</td>\n",
       "      <td>What is the definition of blog?</td>\n",
       "      <td>What is the definition of blogging?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316373</th>\n",
       "      <td>288872</td>\n",
       "      <td>294219</td>\n",
       "      <td>122887</td>\n",
       "      <td>What is the difference between : and ; ?</td>\n",
       "      <td>What is the difference between \":=\" and \"::=\" ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317754</th>\n",
       "      <td>248848</td>\n",
       "      <td>285169</td>\n",
       "      <td>362342</td>\n",
       "      <td>What does this symbol mean?</td>\n",
       "      <td>What does this 'â‰œ' symbol mean?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318279</th>\n",
       "      <td>102122</td>\n",
       "      <td>169021</td>\n",
       "      <td>169022</td>\n",
       "      <td>What is refrigerant?</td>\n",
       "      <td>What is refrigeration?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319355</th>\n",
       "      <td>273876</td>\n",
       "      <td>392410</td>\n",
       "      <td>392411</td>\n",
       "      <td>What is Timing?</td>\n",
       "      <td>What is timee?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "154       3148    6241    6242   \n",
       "170      15678   29935   29936   \n",
       "246     403514  253677  537096   \n",
       "1723    290549   26661   70364   \n",
       "2145    184520  281899  281900   \n",
       "...        ...     ...     ...   \n",
       "316104   45535   81584   81585   \n",
       "316373  288872  294219  122887   \n",
       "317754  248848  285169  362342   \n",
       "318279  102122  169021  169022   \n",
       "319355  273876  392410  392411   \n",
       "\n",
       "                                                question1  \\\n",
       "154            How do I overcome my inferiority complex ?   \n",
       "170                How can I make money as a 13 year old?   \n",
       "246            What are the most haunted places in delhi?   \n",
       "1723    What language is used in Visual Basic? How doe...   \n",
       "2145             What are the best things about modeling?   \n",
       "...                                                   ...   \n",
       "316104                    What is the definition of blog?   \n",
       "316373           What is the difference between : and ; ?   \n",
       "317754                        What does this symbol mean?   \n",
       "318279                               What is refrigerant?   \n",
       "319355                                    What is Timing?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "154             How do I overcome my inferiority complex?             0  \n",
       "170          How can I make money as a thirteen year old?             0  \n",
       "246             What are the most haunted place in delhi?             0  \n",
       "1723    What language is used in Visual Basic? How doe...             0  \n",
       "2145               What are the best things about models?             0  \n",
       "...                                                   ...           ...  \n",
       "316104                What is the definition of blogging?             0  \n",
       "316373    What is the difference between \":=\" and \"::=\" ?             0  \n",
       "317754                    What does this 'â‰œ' symbol mean?             0  \n",
       "318279                             What is refrigeration?             0  \n",
       "319355                                     What is timee?             0  \n",
       "\n",
       "[230 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### SEARCH QUESTIONS WITH SAME TOKENS ###########\n",
    "\n",
    "q1_casted =  cast_list_as_strings(list(train_df[\"question1\"]))\n",
    "q2_casted =  cast_list_as_strings(list(train_df[\"question2\"]))\n",
    "\n",
    "q1 = count_vect.transform(q1_casted)\n",
    "q2 = count_vect.transform(q2_casted)\n",
    "\n",
    "same_tokens_idxs = []\n",
    "for i in range(len(q1_casted)):\n",
    "    same_features = ( q1[i] != q2[i] ).nnz == 0\n",
    "    if same_features:\n",
    "        same_tokens_idxs.append(i)\n",
    "    if i % 500 == 0: print(i)\n",
    "\n",
    "same_tokens_idxs = np.array(same_tokens_idxs)\n",
    "\n",
    "\n",
    "same_tokens = train_df.iloc[same_tokens_idxs]\n",
    "duplicates = same_tokens['is_duplicate'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>327668</td>\n",
       "      <td>454117</td>\n",
       "      <td>345117</td>\n",
       "      <td>How do I study for Honeywell company recruitment?</td>\n",
       "      <td>How do I study for Honeywell company recruitme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>251786</td>\n",
       "      <td>317853</td>\n",
       "      <td>86925</td>\n",
       "      <td>How do I get permanent residence in New Zealand?</td>\n",
       "      <td>How do I get permanent residency in New Zealand?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>351007</td>\n",
       "      <td>479805</td>\n",
       "      <td>479806</td>\n",
       "      <td>What is Open source technology?</td>\n",
       "      <td>What is open source technologies?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>383603</td>\n",
       "      <td>474670</td>\n",
       "      <td>70140</td>\n",
       "      <td>Who will be the next president of US ?</td>\n",
       "      <td>Who will be the next president of US?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>346791</td>\n",
       "      <td>421809</td>\n",
       "      <td>140365</td>\n",
       "      <td>What are some examples of vertebrated animals?</td>\n",
       "      <td>What are some examples of vertebrate animals?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322629</th>\n",
       "      <td>302747</td>\n",
       "      <td>425769</td>\n",
       "      <td>425770</td>\n",
       "      <td>How is the word 'servile' used in a sentence?</td>\n",
       "      <td>How is the word \"servile\" used in a sentence?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322814</th>\n",
       "      <td>272376</td>\n",
       "      <td>390622</td>\n",
       "      <td>390623</td>\n",
       "      <td>Is there any good reading room available near ...</td>\n",
       "      <td>Is there any good reading room available near ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322882</th>\n",
       "      <td>115624</td>\n",
       "      <td>188516</td>\n",
       "      <td>188517</td>\n",
       "      <td>Two hot copper and steel balls long sitting in...</td>\n",
       "      <td>Two hot copper and steel balls long sitting in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323043</th>\n",
       "      <td>256986</td>\n",
       "      <td>372216</td>\n",
       "      <td>372217</td>\n",
       "      <td>Do virus and Bacteria have souls?</td>\n",
       "      <td>Do viruses and bacteria have souls?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323320</th>\n",
       "      <td>76582</td>\n",
       "      <td>130894</td>\n",
       "      <td>130895</td>\n",
       "      <td>What's the best website in which I can take up...</td>\n",
       "      <td>Whats the best website in which I can take up ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1342 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "1       327668  454117  345117   \n",
       "163     251786  317853   86925   \n",
       "873     351007  479805  479806   \n",
       "1644    383603  474670   70140   \n",
       "1857    346791  421809  140365   \n",
       "...        ...     ...     ...   \n",
       "322629  302747  425769  425770   \n",
       "322814  272376  390622  390623   \n",
       "322882  115624  188516  188517   \n",
       "323043  256986  372216  372217   \n",
       "323320   76582  130894  130895   \n",
       "\n",
       "                                                question1  \\\n",
       "1       How do I study for Honeywell company recruitment?   \n",
       "163      How do I get permanent residence in New Zealand?   \n",
       "873                       What is Open source technology?   \n",
       "1644               Who will be the next president of US ?   \n",
       "1857       What are some examples of vertebrated animals?   \n",
       "...                                                   ...   \n",
       "322629      How is the word 'servile' used in a sentence?   \n",
       "322814  Is there any good reading room available near ...   \n",
       "322882  Two hot copper and steel balls long sitting in...   \n",
       "323043                  Do virus and Bacteria have souls?   \n",
       "323320  What's the best website in which I can take up...   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "1       How do I study for Honeywell company recruitme...             1  \n",
       "163      How do I get permanent residency in New Zealand?             1  \n",
       "873                     What is open source technologies?             1  \n",
       "1644                Who will be the next president of US?             1  \n",
       "1857        What are some examples of vertebrate animals?             1  \n",
       "...                                                   ...           ...  \n",
       "322629      How is the word \"servile\" used in a sentence?             1  \n",
       "322814  Is there any good reading room available near ...             1  \n",
       "322882  Two hot copper and steel balls long sitting in...             1  \n",
       "323043                Do viruses and bacteria have souls?             1  \n",
       "323320  Whats the best website in which I can take up ...             1  \n",
       "\n",
       "[1342 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_tokens[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>3148</td>\n",
       "      <td>6241</td>\n",
       "      <td>6242</td>\n",
       "      <td>How do I overcome my inferiority complex ?</td>\n",
       "      <td>How do I overcome my inferiority complex?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>15678</td>\n",
       "      <td>29935</td>\n",
       "      <td>29936</td>\n",
       "      <td>How can I make money as a 13 year old?</td>\n",
       "      <td>How can I make money as a thirteen year old?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>403514</td>\n",
       "      <td>253677</td>\n",
       "      <td>537096</td>\n",
       "      <td>What are the most haunted places in delhi?</td>\n",
       "      <td>What are the most haunted place in delhi?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>290549</td>\n",
       "      <td>26661</td>\n",
       "      <td>70364</td>\n",
       "      <td>What language is used in Visual Basic? How doe...</td>\n",
       "      <td>What language is used in Visual Basic? How doe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>184520</td>\n",
       "      <td>281899</td>\n",
       "      <td>281900</td>\n",
       "      <td>What are the best things about modeling?</td>\n",
       "      <td>What are the best things about models?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316104</th>\n",
       "      <td>45535</td>\n",
       "      <td>81584</td>\n",
       "      <td>81585</td>\n",
       "      <td>What is the definition of blog?</td>\n",
       "      <td>What is the definition of blogging?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316373</th>\n",
       "      <td>288872</td>\n",
       "      <td>294219</td>\n",
       "      <td>122887</td>\n",
       "      <td>What is the difference between : and ; ?</td>\n",
       "      <td>What is the difference between \":=\" and \"::=\" ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317754</th>\n",
       "      <td>248848</td>\n",
       "      <td>285169</td>\n",
       "      <td>362342</td>\n",
       "      <td>What does this symbol mean?</td>\n",
       "      <td>What does this 'â‰œ' symbol mean?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318279</th>\n",
       "      <td>102122</td>\n",
       "      <td>169021</td>\n",
       "      <td>169022</td>\n",
       "      <td>What is refrigerant?</td>\n",
       "      <td>What is refrigeration?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319355</th>\n",
       "      <td>273876</td>\n",
       "      <td>392410</td>\n",
       "      <td>392411</td>\n",
       "      <td>What is Timing?</td>\n",
       "      <td>What is timee?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "154       3148    6241    6242   \n",
       "170      15678   29935   29936   \n",
       "246     403514  253677  537096   \n",
       "1723    290549   26661   70364   \n",
       "2145    184520  281899  281900   \n",
       "...        ...     ...     ...   \n",
       "316104   45535   81584   81585   \n",
       "316373  288872  294219  122887   \n",
       "317754  248848  285169  362342   \n",
       "318279  102122  169021  169022   \n",
       "319355  273876  392410  392411   \n",
       "\n",
       "                                                question1  \\\n",
       "154            How do I overcome my inferiority complex ?   \n",
       "170                How can I make money as a 13 year old?   \n",
       "246            What are the most haunted places in delhi?   \n",
       "1723    What language is used in Visual Basic? How doe...   \n",
       "2145             What are the best things about modeling?   \n",
       "...                                                   ...   \n",
       "316104                    What is the definition of blog?   \n",
       "316373           What is the difference between : and ; ?   \n",
       "317754                        What does this symbol mean?   \n",
       "318279                               What is refrigerant?   \n",
       "319355                                    What is Timing?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "154             How do I overcome my inferiority complex?             0  \n",
       "170          How can I make money as a thirteen year old?             0  \n",
       "246             What are the most haunted place in delhi?             0  \n",
       "1723    What language is used in Visual Basic? How doe...             0  \n",
       "2145               What are the best things about models?             0  \n",
       "...                                                   ...           ...  \n",
       "316104                What is the definition of blogging?             0  \n",
       "316373    What is the difference between \":=\" and \"::=\" ?             0  \n",
       "317754                    What does this 'â‰œ' symbol mean?             0  \n",
       "318279                             What is refrigeration?             0  \n",
       "319355                                     What is timee?             0  \n",
       "\n",
       "[230 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_tokens[~duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
