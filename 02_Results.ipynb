{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn import *\n",
    "import re\n",
    "from SimpleCountVectorizerAMC import *\n",
    "from TFIDFVectorizer import *\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Given an int32 number, print it in English.\"\"\"\n",
    "def int_to_en(num):\n",
    "    d = { 0 : 'zero', 1 : 'one', 2 : 'two', 3 : 'three', 4 : 'four', 5 : 'five',\n",
    "          6 : 'six', 7 : 'seven', 8 : 'eight', 9 : 'nine', 10 : 'ten',\n",
    "          11 : 'eleven', 12 : 'twelve', 13 : 'thirteen', 14 : 'fourteen',\n",
    "          15 : 'fifteen', 16 : 'sixteen', 17 : 'seventeen', 18 : 'eighteen',\n",
    "          19 : 'nineteen', 20 : 'twenty',\n",
    "          30 : 'thirty', 40 : 'forty', 50 : 'fifty', 60 : 'sixty',\n",
    "          70 : 'seventy', 80 : 'eighty', 90 : 'ninety' }\n",
    "    k = 1000\n",
    "    m = k * 1000\n",
    "    b = m * 1000\n",
    "    t = b * 1000\n",
    "\n",
    "    assert(0 <= num)\n",
    "\n",
    "    if (num < 20):\n",
    "        return d[num]\n",
    "\n",
    "    if (num < 100):\n",
    "        if num % 10 == 0: return d[num]\n",
    "        else: return d[num // 10 * 10] + '-' + d[num % 10]\n",
    "\n",
    "    if (num < k):\n",
    "        if num % 100 == 0: return d[num // 100] + ' hundred'\n",
    "        else: return d[num // 100] + ' hundred and ' + int_to_en(num % 100)\n",
    "\n",
    "    if (num < m):\n",
    "        if num % k == 0: return int_to_en(num // k) + ' thousand'\n",
    "        else: return int_to_en(num // k) + ' thousand, ' + int_to_en(num % k)\n",
    "\n",
    "    if (num < b):\n",
    "        if (num % m) == 0: return int_to_en(num // m) + ' million'\n",
    "        else: return int_to_en(num // m) + ' million, ' + int_to_en(num % m)\n",
    "\n",
    "    if (num < t):\n",
    "        if (num % b) == 0: return int_to_en(num // b) + ' billion'\n",
    "        else: return int_to_en(num // b) + ' billion, ' + int_to_en(num % b)\n",
    "\n",
    "    if (num % t == 0): return int_to_en(num // t) + ' trillion'\n",
    "    else: return int_to_en(num // t) + ' trillion, ' + int_to_en(num % t)\n",
    "\n",
    "    raise AssertionError('num is too large: %s' % str(num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/quora_train_data.csv\")\n",
    "test_df = pd.read_csv('./data/quora_test_data.csv')\n",
    "\n",
    "# train_df, test_df = sklearn.model_selection.train_test_split(train_df, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_list_as_strings(mylist):\n",
    "    \"\"\"\n",
    "    return a list of strings\n",
    "    \"\"\"\n",
    "    assert isinstance(mylist, list), f\"the input mylist should be a list it is {type(mylist)}\"\n",
    "    \n",
    "    # return list(map(lambda x: str(x), all_questions)) # Slower\n",
    "    return [str(s) for s in mylist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_questions = cast_list_as_strings(list(train_df.loc[:, 'question1'])+list(train_df.loc[:, 'question2']))\n",
    "print(set(type(x).__name__ for x in all_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_conv(s):\n",
    "    try:\n",
    "        return int_to_en(int(s)).replace(\",\",\"\").replace(\" \",\"_\")\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "\n",
    "def my_doc_cleaner(doc,\n",
    "                  pat=r\"[^a-zA-Z0-9]\"):\n",
    "    # Allow alphanumeric characters\n",
    "    doc_cleaner_pattern=pat\n",
    "    clean_doc_pattern = re.compile(doc_cleaner_pattern)\n",
    "    doc_clean = clean_doc_pattern.sub(\" \", doc)\n",
    "    return doc.lower()\n",
    "\n",
    "\n",
    "# stpw = set(stopwords.words(\"english\"))\n",
    "stpw = []\n",
    "question_words = ['who','what','when','where','why','how']\n",
    "\n",
    "stemmer =  SnowballStemmer(language='english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def my_tokenizer_func(doc, \n",
    "                      ngrams=(1,3), \n",
    "                      numbers_to_words=True,\n",
    "                      stop_words=stpw,\n",
    "                      pat=r\"(?u)\\b\\w\\S*\\w*\\b\",\n",
    "                      duplicate_question_words=question_words,\n",
    "                      lem=True,\n",
    "                      stem=True,\n",
    "                      add_num_tokens=True):\n",
    "    \n",
    "    # Split using a patterm\n",
    "#     pat=r\"(?u)\\b\\w\\w+\\b\"\n",
    "#     pat=r\"(?u)\\b\\w\\S*\\w*\\b\"\n",
    "    token_pattern = re.compile(pat)\n",
    "    lst = token_pattern.findall(doc)\n",
    "    \n",
    "    # Transform numbers into words\n",
    "    if numbers_to_words:\n",
    "        lst = list(map(lambda x: num_conv(x), lst))\n",
    "        \n",
    "    # Drop stopwords \n",
    "    lst = list(filter(lambda x : x not in stop_words, lst))\n",
    "    \n",
    "    # Duplicate key_words\n",
    "    if len(duplicate_question_words)>0:\n",
    "        lst += [value for value in lst if value.lower() in duplicate_question_words]\n",
    "    \n",
    "    #Stemmer\n",
    "    if stem:\n",
    "        lst = list(map(lambda x: stemmer.stem(x), lst))\n",
    "    \n",
    "    #Lemmatizer \n",
    "    if lem:\n",
    "        lst = list(map(lambda x: lemmatizer.lemmatize(x), lst))\n",
    "        \n",
    "    if ngrams==(1,1):\n",
    "        return lst\n",
    "    \n",
    "    # Generate ngrams\n",
    "    lstRet = []\n",
    "    for a in range(ngrams[0], ngrams[1]+1):\n",
    "        if a!=1:\n",
    "            lstRet+=list(zip(*[lst[i:] for i in range(a)]))\n",
    "            \n",
    "    # N-tokens\n",
    "    if add_num_tokens:\n",
    "        lst.append(num_conv(str(len(lst))) + 'tokens')\n",
    "    \n",
    "    return lstRet if ngrams[0]!=1 else lst+lstRet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = SimpleCountVectorizerAMC(\n",
    "    doc_cleaner_func=my_doc_cleaner,\n",
    "    tokenizer_func=my_tokenizer_func\n",
    ")\n",
    "count_vect.fit(all_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_df(df, vectorizer):\n",
    "    \"\"\"\n",
    "    returns a sparse matrix containing the features build by the count vectorizer.\n",
    "    Each row should contain features from question1 and question2.\n",
    "    \"\"\"\n",
    "    q1_casted =  cast_list_as_strings(list(df[\"question1\"]))\n",
    "    q2_casted =  cast_list_as_strings(list(df[\"question2\"]))\n",
    "    \n",
    "    q1 = vectorizer.transform(q1_casted)\n",
    "    q2 = vectorizer.transform(q2_casted)\n",
    "    \n",
    "    X_q1q2 = scipy.sparse.hstack((q1,q2))\n",
    "        \n",
    "    return X_q1q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time X_tr_q1q2 = get_features_from_df(train_df,count_vect)\n",
    "# %time X_te_q1q2  = get_features_from_df(test_df, count_vect)\n",
    "\n",
    "# X_tr_q1q2.shape, train_df.shape, test_df.shape, X_te_q1q2.shape\n",
    "# ((323432, 6166022), (323432, 6), (80858, 6), (80858, 6166022))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[\"is_duplicate\"].values\n",
    "y_test = test_df['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TFIDFVectorizer(count_vect.vocabulary, count_vect.word_to_ind, count_vect.tokenize)\n",
    "tfidf_vectorizer.fit(all_questions)\n",
    "\n",
    "X_tfidf_tr_q1q2 = get_features_from_df(train_df, tfidf_vectorizer)\n",
    "X_tfidf_te_q1q2  = get_features_from_df(test_df, tfidf_vectorizer)\n",
    "\n",
    "X_tfidf_tr_q1q2.shape, train_df.shape, test_df.shape, X_tfidf_te_q1q2.shape\n",
    "# ((323432, 6595608), (323432, 6), (80858, 6), (80858, 6595608))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "N = 10000 # With early stopping\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=N)\n",
    "xgb_model.fit(X_tfidf_tr_q1q2, y_train, \n",
    "              verbose=10, \n",
    "              eval_set=[(X_tfidf_tr_q1q2, y_train),(X_tfidf_te_q1q2, y_test)], \n",
    "              early_stopping_rounds =10,\n",
    "              eval_metric=['auc','logloss'],\n",
    "              )\n",
    "\n",
    "#TRFIDF # [80]\tvalidation_0-auc:0.76871\tvalidation_0-logloss:0.561218\tvalidation_1-auc:0.677593\tvalidation_1-logloss:0.615557\n",
    "#COUNTV # [80]\tvalidation_0-auc:0.739739\tvalidation_0-logloss:0.581786\tvalidation_1-auc:0.738985\tvalidation_1-logloss:0.582385"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "results = xgb_model.evals_result()\n",
    "epochs = len(results['validation_0']['logloss'])\n",
    "x_axis = range(0, epochs)\n",
    "\n",
    "fig = plt.figure(figsize=(20,6))\n",
    "\n",
    "# plot log loss\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "ax.legend()\n",
    "ax.set_ylabel('Log Loss')\n",
    "ax.set_title('XGBoost Log Loss')\n",
    "\n",
    "# plot classification AUC\n",
    "ax = fig.add_subplot(122)\n",
    "ax.plot(x_axis, results['validation_0']['auc'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['auc'], label='Test')\n",
    "ax.legend()\n",
    "ax.set_ylabel('Classification AUC')\n",
    "ax.set_title('XGBoost Classification AUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now().strftime(\"%d.%m_%H.%M\")\n",
    "xgb_model.save_model('models/model_{}.dat'.format(now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters = {'nthread':[4], \n",
    "#               'objective':['binary:logistic'],\n",
    "#               'learning_rate': [0.1,0.5,1], \n",
    "#               'max_depth': [3,5],\n",
    "#               'scale_pos_weight':[1,5,20],\n",
    "#               'min_child_weight': [4,5],\n",
    "#               'silent': [1],\n",
    "#               'subsample': [0.7],\n",
    "#               'colsample_bytree': [0.7, 0.9],\n",
    "#               'n_estimators': [50]}\n",
    "\n",
    "# N = 100\n",
    "# xgb_model = xgb.XGBClassifier(n_estimators=N)\n",
    "# grid = GridSearchCV(xgb_model, parameters,\n",
    "#                     n_jobs = 5, scoring='roc_auc',\n",
    "#                     verbose=True)\n",
    "# grid.fit(X_tr_q1q2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mistakes(clf, X_q1q2, y):\n",
    "\n",
    "    predictions = np.around(clf.predict(X_q1q2)).astype(int)   \n",
    "#     print(y[:10])\n",
    "#     print(predictions[:10])\n",
    "    incorrect_predictions = predictions!=y\n",
    "#     print(incorrect_predictions[:10])\n",
    "#     print(np.where(incorrect_predictions)[:10])\n",
    "    incorrect_indices = np.where(incorrect_predictions)[0]\n",
    "    \n",
    "    if np.sum(incorrect_predictions)==0:\n",
    "        print(\"no mistakes in this df\")\n",
    "    else:\n",
    "        return incorrect_indices, predictions\n",
    "    \n",
    "def print_mistake_k(k, mistake_indices, predictions, df):\n",
    "    print(df.iloc[mistake_indices[k]].question1)\n",
    "    print(df.iloc[mistake_indices[k]].question2)\n",
    "    print(\"true class:\", df.iloc[mistake_indices[k]].is_duplicate)\n",
    "    print(\"prediction:\", predictions[mistake_indices[k]])\n",
    "    \n",
    "def print_mistake_k_and_tokens(k, mistake_indices, predictions,\n",
    "                               X_q1q2, count_vect, clf, df):\n",
    "    q1 = df.iloc[mistake_indices[k]].question1\n",
    "    q2 = df.iloc[mistake_indices[k]].question2\n",
    "    \n",
    "    print(q1)\n",
    "    print(count_vect.tokenize(q1))\n",
    "    print()\n",
    "    print(q2)\n",
    "    print(count_vect.tokenize(q2))\n",
    "    print()\n",
    "    print(\"true class:\", df.iloc[mistake_indices[k]].is_duplicate)\n",
    "    print(\"prediction:\", predictions[mistake_indices[k]])\n",
    "    print()\n",
    "    print(\"Probability vector: [P(0|x), P(1|x)]:\")\n",
    "    print(clf.predict_proba(X_q1q2)[mistake_indices[k],:])\n",
    "    \n",
    "    \n",
    "def hist_errors(mistake_indices, predictions,\n",
    "                               X_q1q2, count_vect, clf, df):\n",
    "    qs = df.iloc[mistake_indices][['question1', 'question2']]\n",
    "    qs['true_class']=df.iloc[mistake_indices].is_duplicate\n",
    "    qs['prediction']=predictions[mistake_indices]\n",
    "    qs['P(1|x)']=clf.predict_proba(X_q1q2)[mistake_indices,:][:,1]\n",
    "    qs = qs.reset_index(drop=True)\n",
    "    return qs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistake_indices, predictions = get_mistakes(xgb_model, X_te_q1q2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.Booster({'nthread': 4})  # init booster\n",
    "bst.load_model('models/model_{}.dat'.format(now))  # load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_loaded_model = xgb.XGBClassifier()\n",
    "xgb_loaded_model._Booster=bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistake_indices, predictions = get_mistakes(xgb_loaded_model, X_te_q1q2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mistake_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mistake_k(0, mistake_indices, predictions, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mistake_k_and_tokens(0, mistake_indices, predictions,\n",
    "                           X_te_q1q2, count_vect, xgb_loaded_model, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = hist_errors(mistake_indices, predictions,\n",
    "                           X_te_q1q2, count_vect, xgb_loaded_model, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_rows', N)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read mistakes\n",
    "qs.head(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = sklearn.linear_model.LogisticRegression(solver=\"liblinear\", verbose=1, max_iter=100)\n",
    "logistic.fit(X_tfidf_tr_q1q2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic.score(X_tfidf_tr_q1q2, y_train), logistic.score(X_tfidf_te_q1q2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistake_indices, predictions = get_mistakes(logistic, X_tfidf_te_q1q2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mistake_k(0, mistake_indices, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mistake_k_and_tokens(0, mistake_indices, predictions,\n",
    "                           X_tfidf_te_q1q2, tfidf_vectorizer, logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "######### SEARCH QUESTIONS WITH SAME TOKENS ###########\n",
    "\n",
    "q1_casted =  cast_list_as_strings(list(train_df[\"question1\"]))\n",
    "q2_casted =  cast_list_as_strings(list(train_df[\"question2\"]))\n",
    "\n",
    "q1 = count_vect.transform(q1_casted)\n",
    "q2 = count_vect.transform(q2_casted)\n",
    "\n",
    "same_tokens_idxs = []\n",
    "for i in range(len(q1_casted)):\n",
    "    same_features = ( q1[i] != q2[i] ).nnz == 0\n",
    "    if same_features:\n",
    "        same_tokens_idxs.append(i)\n",
    "    if i % 500 == 0: print(i)\n",
    "\n",
    "same_tokens_idxs = np.array(same_tokens_idxs)\n",
    "\n",
    "\n",
    "same_tokens = train_df.iloc[same_tokens_idxs]\n",
    "duplicates = same_tokens['is_duplicate'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_tokens[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_tokens[~duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
